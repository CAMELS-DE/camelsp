{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nordrhein-Westfalen\n",
    "\n",
    "Every federal state is represented by its own input directory and is processed into a NUTS level 2 directory containing a sub-folder for each discharge location. These folder names are derived from NUTS and reflect the CAMELS id. The NUTS level 2 code for Nordrhein-Westfalen is `DEA`.\n",
    "\n",
    "To pre-process the data, you need to write (at least) two functions. One should extract all metadata and condense it into a single `pandas.DataFrame`. This is used to build the folder structure and derive the ids.\n",
    "The second function has to take an id, as provided by the state authorities, called `provider_id` and return a `pandas.DataFrame` with the transformed data. The dataframe needs the three columns `['date', 'q' | 'w', 'flag']`.\n",
    "\n",
    "For easier and unified output handling, the `camelsp` package contains a context object called `Bundesland`. It takes a number of names and abbreviations to identify the correct federal state and returns an object that holds helper and save functions.\n",
    "\n",
    "The context saves files as needed and can easily be changed to save files with different strategies, ie. fill missing data with NaN, merge data into a single file, create files for each variable or pack everything together into a netcdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.errors import ParserError\n",
    "import os\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from typing import Union, Dict\n",
    "import patoolib\n",
    "from glob import glob\n",
    "from datetime import datetime as dt\n",
    "from dateparser import parse\n",
    "import warnings\n",
    "from io import StringIO\n",
    "\n",
    "from camelsp import Bundesland\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The context can also be instantiated as any regular Python class, ie. to load only the default input data path, that we will user later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alexander/Github/camels/camelsp/input_data/NRW_Nordrhein-Westfalen'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the context also makes the input path available, if camelsp was install locally\n",
    "BASE = Bundesland('NRW').input_path\n",
    "BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patool: Extracting /home/alexander/Github/camels/camelsp/input_data/NRW_Nordrhein-Westfalen/Q&W.rar ...\n",
      "patool: running /usr/bin/unrar x -- /home/alexander/Github/camels/camelsp/input_data/NRW_Nordrhein-Westfalen/Q&W.rar\n",
      "patool:     with cwd='/home/alexander/Github/camels/camelsp/input_data/NRW_Nordrhein-Westfalen'\n",
      "patool: ... /home/alexander/Github/camels/camelsp/input_data/NRW_Nordrhein-Westfalen/Q&W.rar extracted to `/home/alexander/Github/camels/camelsp/input_data/NRW_Nordrhein-Westfalen'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/alexander/Github/camels/camelsp/input_data/NRW_Nordrhein-Westfalen'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove everything from BASE folder except Q&W.rar to ensure that data is extracted freshly and is up to date\n",
    "for f in glob(f\"{BASE}/*[!*.rar]\"):\n",
    "    os.remove(f)\n",
    "\n",
    "# extract rar archive\n",
    "patoolib.extract_archive(f\"{BASE}/Q&W.rar\", outdir=BASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAME</th>\n",
       "      <th>ORT</th>\n",
       "      <th>NULLPUNKT</th>\n",
       "      <th>STATIONIER</th>\n",
       "      <th>GEBFLAECHE</th>\n",
       "      <th>UTMZONE</th>\n",
       "      <th>KOORDX</th>\n",
       "      <th>KOORDY</th>\n",
       "      <th>KOMMENTAR</th>\n",
       "      <th>GEBIETSKEN</th>\n",
       "      <th>Gewässerkennzahl</th>\n",
       "      <th>Gewässer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ahmsen</td>\n",
       "      <td>4639000000100</td>\n",
       "      <td>64.285</td>\n",
       "      <td>27.158</td>\n",
       "      <td>593.00</td>\n",
       "      <td>32U</td>\n",
       "      <td>479549.677600</td>\n",
       "      <td>5.771202e+06</td>\n",
       "      <td>Grundmessstelle des Landes (GL)</td>\n",
       "      <td>4639.0</td>\n",
       "      <td>46</td>\n",
       "      <td>Werre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albersloh</td>\n",
       "      <td>3259000000100</td>\n",
       "      <td>48.678</td>\n",
       "      <td>27.470</td>\n",
       "      <td>321.58</td>\n",
       "      <td>32U</td>\n",
       "      <td>412463.350631</td>\n",
       "      <td>5.748891e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3259.0</td>\n",
       "      <td>32</td>\n",
       "      <td>Werse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Altena</td>\n",
       "      <td>2766930000100</td>\n",
       "      <td>154.225</td>\n",
       "      <td>29.700</td>\n",
       "      <td>1190.00</td>\n",
       "      <td>32U</td>\n",
       "      <td>407683.711900</td>\n",
       "      <td>5.682847e+06</td>\n",
       "      <td>Talsperrenbeeinflussung ab 1968 (Biggetalsperre)</td>\n",
       "      <td>276693.0</td>\n",
       "      <td>2766</td>\n",
       "      <td>Lenne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Altenbeken 2</td>\n",
       "      <td>2781610000200</td>\n",
       "      <td>215.958</td>\n",
       "      <td>11.990</td>\n",
       "      <td>20.50</td>\n",
       "      <td>32U</td>\n",
       "      <td>494359.426900</td>\n",
       "      <td>5.734473e+06</td>\n",
       "      <td>Grundmeßstelle des Landes (GL)</td>\n",
       "      <td>278161.0</td>\n",
       "      <td>27816</td>\n",
       "      <td>Beke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Altenburg 1</td>\n",
       "      <td>2823900000200</td>\n",
       "      <td>82.651</td>\n",
       "      <td>62.440</td>\n",
       "      <td>958.76</td>\n",
       "      <td>32U</td>\n",
       "      <td>315309.586100</td>\n",
       "      <td>5.641695e+06</td>\n",
       "      <td>Grundmessstelle</td>\n",
       "      <td>28239.0</td>\n",
       "      <td>282</td>\n",
       "      <td>Rur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Westtuennen</td>\n",
       "      <td>2786700000100</td>\n",
       "      <td>57.572</td>\n",
       "      <td>3.970</td>\n",
       "      <td>414.90</td>\n",
       "      <td>32U</td>\n",
       "      <td>421634.000000</td>\n",
       "      <td>5.724518e+06</td>\n",
       "      <td>Grundmessstelle des Landes (GL)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2786</td>\n",
       "      <td>Ahse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Wetter_Wengern_1</td>\n",
       "      <td>2769169000100</td>\n",
       "      <td>84.805</td>\n",
       "      <td>0.480</td>\n",
       "      <td>17.58</td>\n",
       "      <td>32U</td>\n",
       "      <td>384656.787100</td>\n",
       "      <td>5.695710e+06</td>\n",
       "      <td>Grundmeßstelle des Landes (GL)</td>\n",
       "      <td>2769169.0</td>\n",
       "      <td>276916</td>\n",
       "      <td>Elbsche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>Wettringen B70</td>\n",
       "      <td>9286291000300</td>\n",
       "      <td>41.504</td>\n",
       "      <td>6.330</td>\n",
       "      <td>175.07</td>\n",
       "      <td>32U</td>\n",
       "      <td>385480.262390</td>\n",
       "      <td>5.786270e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>928629.0</td>\n",
       "      <td>92862</td>\n",
       "      <td>Steinfurter Aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Wt-Kluserbrücke</td>\n",
       "      <td>2736510000100</td>\n",
       "      <td>142.226</td>\n",
       "      <td>49.240</td>\n",
       "      <td>337.82</td>\n",
       "      <td>32U</td>\n",
       "      <td>371494.000000</td>\n",
       "      <td>5.679856e+06</td>\n",
       "      <td>Durch mehrere Talsperren beeinflusst. Seit 01....</td>\n",
       "      <td>273651.0</td>\n",
       "      <td>2736</td>\n",
       "      <td>Wupper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Zerkall 1</td>\n",
       "      <td>2823500000100</td>\n",
       "      <td>171.232</td>\n",
       "      <td>94.330</td>\n",
       "      <td>787.00</td>\n",
       "      <td>32U</td>\n",
       "      <td>320063.421100</td>\n",
       "      <td>5.618751e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28235.0</td>\n",
       "      <td>282</td>\n",
       "      <td>Rur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 NAME            ORT  NULLPUNKT  STATIONIER  GEBFLAECHE  \\\n",
       "0              Ahmsen  4639000000100     64.285      27.158      593.00   \n",
       "1           Albersloh  3259000000100     48.678      27.470      321.58   \n",
       "2              Altena  2766930000100    154.225      29.700     1190.00   \n",
       "3        Altenbeken 2  2781610000200    215.958      11.990       20.50   \n",
       "4         Altenburg 1  2823900000200     82.651      62.440      958.76   \n",
       "..                ...            ...        ...         ...         ...   \n",
       "214       Westtuennen  2786700000100     57.572       3.970      414.90   \n",
       "215  Wetter_Wengern_1  2769169000100     84.805       0.480       17.58   \n",
       "216    Wettringen B70  9286291000300     41.504       6.330      175.07   \n",
       "217   Wt-Kluserbrücke  2736510000100    142.226      49.240      337.82   \n",
       "218         Zerkall 1  2823500000100    171.232      94.330      787.00   \n",
       "\n",
       "    UTMZONE         KOORDX        KOORDY  \\\n",
       "0       32U  479549.677600  5.771202e+06   \n",
       "1       32U  412463.350631  5.748891e+06   \n",
       "2       32U  407683.711900  5.682847e+06   \n",
       "3       32U  494359.426900  5.734473e+06   \n",
       "4       32U  315309.586100  5.641695e+06   \n",
       "..      ...            ...           ...   \n",
       "214     32U  421634.000000  5.724518e+06   \n",
       "215     32U  384656.787100  5.695710e+06   \n",
       "216     32U  385480.262390  5.786270e+06   \n",
       "217     32U  371494.000000  5.679856e+06   \n",
       "218     32U  320063.421100  5.618751e+06   \n",
       "\n",
       "                                             KOMMENTAR  GEBIETSKEN  \\\n",
       "0                      Grundmessstelle des Landes (GL)      4639.0   \n",
       "1                                                  NaN      3259.0   \n",
       "2     Talsperrenbeeinflussung ab 1968 (Biggetalsperre)    276693.0   \n",
       "3                       Grundmeßstelle des Landes (GL)    278161.0   \n",
       "4                                      Grundmessstelle     28239.0   \n",
       "..                                                 ...         ...   \n",
       "214                    Grundmessstelle des Landes (GL)         NaN   \n",
       "215                     Grundmeßstelle des Landes (GL)   2769169.0   \n",
       "216                                                NaN    928629.0   \n",
       "217  Durch mehrere Talsperren beeinflusst. Seit 01....    273651.0   \n",
       "218                                                NaN     28235.0   \n",
       "\n",
       "     Gewässerkennzahl        Gewässer  \n",
       "0                  46           Werre  \n",
       "1                  32           Werse  \n",
       "2                2766           Lenne  \n",
       "3               27816            Beke  \n",
       "4                 282             Rur  \n",
       "..                ...             ...  \n",
       "214              2786            Ahse  \n",
       "215            276916         Elbsche  \n",
       "216             92862  Steinfurter Aa  \n",
       "217              2736          Wupper  \n",
       "218               282             Rur  \n",
       "\n",
       "[219 rows x 12 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with Bundesland('NRW') as bl:\n",
    "    metadata = pd.read_excel(os.path.join(bl.input_path, 'Stammdaten_CAMELS.xlsx'))\n",
    "\n",
    "metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata reader\n",
    "\n",
    "Define the function that extracts / reads and eventually merges all metadata for this federal state. You can develop the function here, without using the Bundesland context and then later use the context to pass extracted metadata. The Context has a function for saving *raw* metadata, that takes a `pandas.DataFrame` and needs you to identify the id column.\n",
    "Here, *raw* refers to provider metadata, that has not yet been transformed into the CAMELS-de Metadata schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the id column will be ORT\n",
    "id_column = 'ORT'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## file extract and parse\n",
    "\n",
    "Here, we need to process the filename as the `'Ort'` is contained in the filename. Looks like the metadata header is **always** to line 32, indicating a finished header by `YTYP;`. Verify this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in glob(os.path.join(BASE, 'Datenanfrage_CAMELS_*')):\n",
    "    df = pd.read_csv(fname, encoding='latin1', sep=';', usecols=[0,1], nrows=32, header=None)\n",
    "    if df.iloc[31, 0] != 'YTYP':\n",
    "        print(fname)\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's will make our lifes way easier. Now go for all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 437/437 [08:29<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 437 metadata headers and 437 data files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get all file names\n",
    "filelist = glob(os.path.join(BASE, 'Datenanfrage_CAMELS_*'))\n",
    "\n",
    "# container for meta-header and dataframes\n",
    "meta = []\n",
    "data = []\n",
    "\n",
    "# go for each file\n",
    "for fname in tqdm(filelist):\n",
    "    # open\n",
    "    with open(fname, 'rb') as f:\n",
    "        txt = f.read().decode('latin1')\n",
    "    \n",
    "    # split header\n",
    "    header = txt.splitlines()[:32]\n",
    "    \n",
    "    # build the meta by hand\n",
    "    tups = [l.split(';') for l in header[:-1]]\n",
    "    meta_dict = {t[0]: t[1] for t in tups}\n",
    "\n",
    "    # check the parameter\n",
    "    if meta_dict['Parameter'] == 'Wasserstand':\n",
    "        variable = 'w'\n",
    "    elif meta_dict['Parameter'] == 'Abfluss':\n",
    "        variable = 'q'\n",
    "    else:\n",
    "        raise RuntimeError(f\"Unknown Parameter: {meta_dict['Parameter']}\")\n",
    "\n",
    "    meta.append(meta_dict)\n",
    "    \n",
    "    # now get the body\n",
    "    body = txt.splitlines()[32:]\n",
    "\n",
    "    # now this stupid check\n",
    "    second_header = [i for i, l in enumerate(body) if l.startswith('Station')]\n",
    "    if len(second_header) > 0:\n",
    "        # THERE IS A SECOND HEADER IN THE FILE !!!! come on!\n",
    "        body = body[:second_header[0]]\n",
    "    \n",
    "    # write to buffer\n",
    "    buffer = StringIO('\\n'.join(body))\n",
    "    buffer.seek(0)\n",
    "    \n",
    "    # read from memory\n",
    "    df_data = pd.read_csv(buffer, sep=';', usecols=[0,1], skiprows=32, decimal=',', header=None, na_values='LUECKE', parse_dates=[0])\n",
    "    \n",
    "    df_data.columns = ['date', variable]\n",
    "    df_data['flag'] = np.NaN\n",
    "    \n",
    "    # append\n",
    "    data.append(df_data)\n",
    "    \n",
    "    \n",
    "print(f\"Parsed {len(meta)} metadata headers and {len(data)} data files\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was really stupid. Ok. Check the metadata from the data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station</th>\n",
       "      <th>Stationsnummer</th>\n",
       "      <th>Unterbezeichnung</th>\n",
       "      <th>Einzugsgebiet</th>\n",
       "      <th>Pegelnullpunkt</th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Einheit</th>\n",
       "      <th>Aussage</th>\n",
       "      <th>Lebenslauf</th>\n",
       "      <th>Zeitangabe</th>\n",
       "      <th>...</th>\n",
       "      <th>PARMERKMAL</th>\n",
       "      <th>PUBLIZIERT</th>\n",
       "      <th>QUELLE</th>\n",
       "      <th>REIHENART</th>\n",
       "      <th>VERSION</th>\n",
       "      <th>X</th>\n",
       "      <th>XDISTANZ</th>\n",
       "      <th>XEINHEIT</th>\n",
       "      <th>XFAKTOR</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kreuztal</td>\n",
       "      <td>2721459000100</td>\n",
       "      <td></td>\n",
       "      <td>63,40 km²</td>\n",
       "      <td>273,894 mNHN (aktuell)</td>\n",
       "      <td>Abfluss</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>Mittelwert</td>\n",
       "      <td>MITTEL('2721459000100.qk0',d)</td>\n",
       "      <td>Linke Seite des Zeitintervalls mit Intervallwert</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>P</td>\n",
       "      <td>Z</td>\n",
       "      <td>0</td>\n",
       "      <td>429430</td>\n",
       "      <td>T</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>5645719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Liesborn</td>\n",
       "      <td>2784650000100</td>\n",
       "      <td></td>\n",
       "      <td>66,30 km²</td>\n",
       "      <td>73,405 mNHN (aktuell)</td>\n",
       "      <td>Wasserstand</td>\n",
       "      <td>cm</td>\n",
       "      <td>Mittelwert</td>\n",
       "      <td>MITTEL('2784650000100.wk4',d)</td>\n",
       "      <td>Linke Seite des Zeitintervalls mit Intervallwert</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>P</td>\n",
       "      <td>Z</td>\n",
       "      <td>0</td>\n",
       "      <td>449139</td>\n",
       "      <td>T</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>5729507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Veert</td>\n",
       "      <td>2850000000200</td>\n",
       "      <td></td>\n",
       "      <td>0,00 km²</td>\n",
       "      <td>22,376 mNHN (aktuell)</td>\n",
       "      <td>Wasserstand</td>\n",
       "      <td>cm</td>\n",
       "      <td>Mittelwert</td>\n",
       "      <td>MITTEL('2850000000200.wk2',d)</td>\n",
       "      <td>Linke Seite des Zeitintervalls mit Intervallwert</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>P</td>\n",
       "      <td>Z</td>\n",
       "      <td>0</td>\n",
       "      <td>313366</td>\n",
       "      <td>T</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>5710953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Raumland</td>\n",
       "      <td>4281490000100</td>\n",
       "      <td></td>\n",
       "      <td>84,70 km²</td>\n",
       "      <td>400,254 mNHN (aktuell)</td>\n",
       "      <td>Wasserstand</td>\n",
       "      <td>cm</td>\n",
       "      <td>Mittelwert</td>\n",
       "      <td>MITTEL('4281490000100.wk3',d)</td>\n",
       "      <td>Linke Seite des Zeitintervalls mit Intervallwert</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>P</td>\n",
       "      <td>Z</td>\n",
       "      <td>0</td>\n",
       "      <td>456965</td>\n",
       "      <td>T</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>5653501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hörstel</td>\n",
       "      <td>3448390000200</td>\n",
       "      <td></td>\n",
       "      <td>88,66 km²</td>\n",
       "      <td>40,018 mDHHN92 (aktuell)</td>\n",
       "      <td>Wasserstand</td>\n",
       "      <td>cm</td>\n",
       "      <td>Mittelwert</td>\n",
       "      <td>MITTEL('3448390000200.wk3',d)</td>\n",
       "      <td>Linke Seite des Zeitintervalls mit Intervallwert</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>P</td>\n",
       "      <td>Z</td>\n",
       "      <td>0</td>\n",
       "      <td>403784</td>\n",
       "      <td>T</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>5797597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Station Stationsnummer Unterbezeichnung Einzugsgebiet  \\\n",
       "0  Kreuztal  2721459000100                      63,40 km²   \n",
       "1  Liesborn  2784650000100                      66,30 km²   \n",
       "2     Veert  2850000000200                       0,00 km²   \n",
       "3  Raumland  4281490000100                      84,70 km²   \n",
       "4   Hörstel  3448390000200                      88,66 km²   \n",
       "\n",
       "              Pegelnullpunkt    Parameter Einheit     Aussage  \\\n",
       "0    273,894 mNHN (aktuell)      Abfluss    m³/s  Mittelwert   \n",
       "1     73,405 mNHN (aktuell)  Wasserstand      cm  Mittelwert   \n",
       "2     22,376 mNHN (aktuell)  Wasserstand      cm  Mittelwert   \n",
       "3    400,254 mNHN (aktuell)  Wasserstand      cm  Mittelwert   \n",
       "4  40,018 mDHHN92 (aktuell)  Wasserstand      cm  Mittelwert   \n",
       "\n",
       "                       Lebenslauf  \\\n",
       "0   MITTEL('2721459000100.qk0',d)   \n",
       "1   MITTEL('2784650000100.wk4',d)   \n",
       "2   MITTEL('2850000000200.wk2',d)   \n",
       "3   MITTEL('4281490000100.wk3',d)   \n",
       "4   MITTEL('3448390000200.wk3',d)   \n",
       "\n",
       "                                         Zeitangabe  ... PARMERKMAL  \\\n",
       "0  Linke Seite des Zeitintervalls mit Intervallwert  ...              \n",
       "1  Linke Seite des Zeitintervalls mit Intervallwert  ...              \n",
       "2  Linke Seite des Zeitintervalls mit Intervallwert  ...              \n",
       "3  Linke Seite des Zeitintervalls mit Intervallwert  ...              \n",
       "4  Linke Seite des Zeitintervalls mit Intervallwert  ...              \n",
       "\n",
       "  PUBLIZIERT QUELLE REIHENART VERSION       X XDISTANZ XEINHEIT XFAKTOR  \\\n",
       "0       True      P         Z       0  429430        T                1   \n",
       "1       True      P         Z       0  449139        T                1   \n",
       "2       True      P         Z       0  313366        T                1   \n",
       "3       True      P         Z       0  456965        T                1   \n",
       "4       True      P         Z       0  403784        T                1   \n",
       "\n",
       "         Y  \n",
       "0  5645719  \n",
       "1  5729507  \n",
       "2  5710953  \n",
       "3  5653501  \n",
       "4  5797597  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra = pd.DataFrame(meta).drop('Gewässer', axis=1)\n",
    "extra.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to left-join the data, as each Stationsnummer exists twice. Thus, it is only the combination of Stationsnummer and variable, that makes the data unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['Station', 'Stationsnummer', 'Unterbezeichnung', 'Einzugsgebiet',\n       'Pegelnullpunkt', 'Parameter', 'Einheit', 'Aussage', 'Lebenslauf',\n       'Zeitangabe', 'DEFART', 'FTOLERANZ', 'GUELTBIS', 'GUELTVON',\n       'HAUPTREIHE', 'HERKUNFT', 'HOEHE', 'MESSGENAU', 'NWGRENZE',\n       'PARMERKMAL', 'PUBLIZIERT', 'QUELLE', 'REIHENART', 'VERSION', 'X',\n       'XDISTANZ', 'XEINHEIT', 'XFAKTOR', 'Y'],\n      dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/alexander/Github/camels/camelsp/scripts/preprocess_dea.ipynb Cell 17\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/alexander/Github/camels/camelsp/scripts/preprocess_dea.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m metadata \u001b[39m=\u001b[39m extra\u001b[39m.\u001b[39;49mdrop(\u001b[39m'\u001b[39;49m\u001b[39mKOMMENTAR\u001b[39;49m\u001b[39m'\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mjoin(metadata\u001b[39m.\u001b[39;49mset_index(metadata\u001b[39m.\u001b[39;49mORT\u001b[39m.\u001b[39;49mastype(\u001b[39mstr\u001b[39;49m)), on\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mStationsnummer\u001b[39;49m\u001b[39m'\u001b[39;49m, how\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mleft\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/alexander/Github/camels/camelsp/scripts/preprocess_dea.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m metadata\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:9969\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[1;32m   9806\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mjoin\u001b[39m(\n\u001b[1;32m   9807\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   9808\u001b[0m     other: DataFrame \u001b[39m|\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[DataFrame \u001b[39m|\u001b[39m Series],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9814\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   9815\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m   9816\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   9817\u001b[0m \u001b[39m    Join columns of another DataFrame.\u001b[39;00m\n\u001b[1;32m   9818\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9967\u001b[0m \u001b[39m    5  K1  A5   B1\u001b[39;00m\n\u001b[1;32m   9968\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 9969\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_join_compat(\n\u001b[1;32m   9970\u001b[0m         other,\n\u001b[1;32m   9971\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m   9972\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[1;32m   9973\u001b[0m         lsuffix\u001b[39m=\u001b[39;49mlsuffix,\n\u001b[1;32m   9974\u001b[0m         rsuffix\u001b[39m=\u001b[39;49mrsuffix,\n\u001b[1;32m   9975\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m   9976\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m   9977\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:10008\u001b[0m, in \u001b[0;36mDataFrame._join_compat\u001b[0;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[1;32m   9998\u001b[0m     \u001b[39mif\u001b[39;00m how \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcross\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   9999\u001b[0m         \u001b[39mreturn\u001b[39;00m merge(\n\u001b[1;32m  10000\u001b[0m             \u001b[39mself\u001b[39m,\n\u001b[1;32m  10001\u001b[0m             other,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10006\u001b[0m             validate\u001b[39m=\u001b[39mvalidate,\n\u001b[1;32m  10007\u001b[0m         )\n\u001b[0;32m> 10008\u001b[0m     \u001b[39mreturn\u001b[39;00m merge(\n\u001b[1;32m  10009\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m  10010\u001b[0m         other,\n\u001b[1;32m  10011\u001b[0m         left_on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m  10012\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[1;32m  10013\u001b[0m         left_index\u001b[39m=\u001b[39;49mon \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m  10014\u001b[0m         right_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m  10015\u001b[0m         suffixes\u001b[39m=\u001b[39;49m(lsuffix, rsuffix),\n\u001b[1;32m  10016\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m  10017\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m  10018\u001b[0m     )\n\u001b[1;32m  10019\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m  10020\u001b[0m     \u001b[39mif\u001b[39;00m on \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:125\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    109\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    110\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m    111\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[1;32m    112\u001b[0m         left,\n\u001b[1;32m    113\u001b[0m         right,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m         validate\u001b[39m=\u001b[39mvalidate,\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 125\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result(copy\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:778\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_indicator_pre_merge(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright)\n\u001b[1;32m    776\u001b[0m join_index, left_indexer, right_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_join_info()\n\u001b[0;32m--> 778\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reindex_and_concat(\n\u001b[1;32m    779\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[39m=\u001b[39;49mcopy\n\u001b[1;32m    780\u001b[0m )\n\u001b[1;32m    781\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_type)\n\u001b[1;32m    783\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindicator:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:732\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[0;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[1;32m    729\u001b[0m left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft[:]\n\u001b[1;32m    730\u001b[0m right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright[:]\n\u001b[0;32m--> 732\u001b[0m llabels, rlabels \u001b[39m=\u001b[39m _items_overlap_with_suffix(\n\u001b[1;32m    733\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mleft\u001b[39m.\u001b[39;49m_info_axis, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mright\u001b[39m.\u001b[39;49m_info_axis, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuffixes\n\u001b[1;32m    734\u001b[0m )\n\u001b[1;32m    736\u001b[0m \u001b[39mif\u001b[39;00m left_indexer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    737\u001b[0m     \u001b[39m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[39m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m     \u001b[39m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[1;32m    740\u001b[0m     lmgr \u001b[39m=\u001b[39m left\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39mreindex_indexer(\n\u001b[1;32m    741\u001b[0m         join_index,\n\u001b[1;32m    742\u001b[0m         left_indexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    747\u001b[0m         use_na_proxy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    748\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py:2461\u001b[0m, in \u001b[0;36m_items_overlap_with_suffix\u001b[0;34m(left, right, suffixes)\u001b[0m\n\u001b[1;32m   2458\u001b[0m lsuffix, rsuffix \u001b[39m=\u001b[39m suffixes\n\u001b[1;32m   2460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m lsuffix \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m rsuffix:\n\u001b[0;32m-> 2461\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcolumns overlap but no suffix specified: \u001b[39m\u001b[39m{\u001b[39;00mto_rename\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   2463\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrenamer\u001b[39m(x, suffix):\n\u001b[1;32m   2464\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2465\u001b[0m \u001b[39m    Rename the left and right indices.\u001b[39;00m\n\u001b[1;32m   2466\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[39m    x : renamed column name\u001b[39;00m\n\u001b[1;32m   2478\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['Station', 'Stationsnummer', 'Unterbezeichnung', 'Einzugsgebiet',\n       'Pegelnullpunkt', 'Parameter', 'Einheit', 'Aussage', 'Lebenslauf',\n       'Zeitangabe', 'DEFART', 'FTOLERANZ', 'GUELTBIS', 'GUELTVON',\n       'HAUPTREIHE', 'HERKUNFT', 'HOEHE', 'MESSGENAU', 'NWGRENZE',\n       'PARMERKMAL', 'PUBLIZIERT', 'QUELLE', 'REIHENART', 'VERSION', 'X',\n       'XDISTANZ', 'XEINHEIT', 'XFAKTOR', 'Y'],\n      dtype='object')"
     ]
    }
   ],
   "source": [
    "metadata = extra.drop('KOMMENTAR', axis=1).join(metadata.set_index(metadata.ORT.astype(str)), on='Stationsnummer', how='left')\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build and id column\n",
    "metadata['ID'] = metadata.apply(lambda r: r.Stationsnummer + '_' + r.Parameter, axis=1)\n",
    "\n",
    "id_column = 'ID'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally run\n",
    "\n",
    "Now, the Q and W data can be extracted. The cool thing is, that all the id creation, data creation, merging and the mapping from our ids to the original ids and files is done by the context. This is helpful, as we less likely screw something up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nuts_id    provider_id                              path\n",
      "0  DEA10000  2721459000100  ./DEA/DEA10000/DEA10000_data.csv\n",
      "1  DEA10010  2784650000100  ./DEA/DEA10010/DEA10010_data.csv\n",
      "2  DEA10020  2850000000200  ./DEA/DEA10020/DEA10020_data.csv\n",
      "3  DEA10030  4281490000100  ./DEA/DEA10030/DEA10030_data.csv\n",
      "4  DEA10040  3448390000200  ./DEA/DEA10040/DEA10040_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 437/437 [00:21<00:00, 20.64it/s]\n"
     ]
    }
   ],
   "source": [
    "with Bundesland('NRW') as bl:\n",
    "    # save the metadata\n",
    "    bl.save_raw_metadata(metadata, 'Stationsnummer', overwrite=True)\n",
    "\n",
    "    # for reference, call the nuts-mapping as table\n",
    "    nuts_map = bl.nuts_table\n",
    "    print(nuts_map.head())\n",
    "\n",
    "    \n",
    "    with warnings.catch_warnings(record=True) as warns:\n",
    "        for m, df in tqdm(zip(meta, data), total=len(meta)):\n",
    "            # check the meta\n",
    "            provider_id = str(m['Stationsnummer'])\n",
    "            bl.save_timeseries(df, provider_id)\n",
    "\n",
    "        # check if there were warnings (there are warnings)\n",
    "        if len(warns) > 0:\n",
    "            log_path = bl.save_warnings(warns)\n",
    "            print(f\"There were warnings during the processing. The log can be found at: {log_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
