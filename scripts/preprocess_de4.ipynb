{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brandenburg\n",
    "\n",
    "Every federal state is represented by its own input directory and is processed into a NUTS level 2 directory containing a sub-folder for each discharge location. These folder names are derived from NUTS and reflect the CAMELS id. The NUTS level 2 code for Brandenburg is `DE4`.\n",
    "\n",
    "To pre-process the data, you need to write (at least) two functions. One should extract all metadata and condense it into a single `pandas.DataFrame`. This is used to build the folder structure and derive the ids.\n",
    "The second function has to take an id, as provided by the state authorities, called `provider_id` and return a `pandas.DataFrame` with the transformed data. The dataframe needs the three columns `['date', 'q' | 'w', 'flag']`.\n",
    "\n",
    "For easier and unified output handling, the `camelsp` package contains a context object called `Bundesland`. It takes a number of names and abbreviations to identify the correct federal state and returns an object that holds helper and save functions.\n",
    "\n",
    "The context saves files as needed and can easily be changed to save files with different strategies, ie. fill missing data with NaN, merge data into a single file, create files for each variable or pack everything together into a netcdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas.errors import ParserError\n",
    "import os\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from typing import Union, Dict, Tuple\n",
    "import zipfile\n",
    "from datetime import datetime as dt\n",
    "from io import StringIO\n",
    "import warnings\n",
    "from dateparser import parse\n",
    "\n",
    "from camelsp import Bundesland"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The context can also be instantiated as any regular Python class, ie. to load only the default input data path, that we will user later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alexander/Github/camels/camelsp/input_data/BR_Brandenburg'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the context also makes the input path available, if camelsp was install locally\n",
    "BASE = Bundesland('Brandenburg').input_path\n",
    "BASE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata reader\n",
    "\n",
    "Define the function that extracts / reads and eventually merges all metadata for this federal state. You can develop the function here, without using the Bundesland context and then later use the context to pass extracted metadata. The Context has a function for saving *raw* metadata, that takes a `pandas.DataFrame` and needs you to identify the id column.\n",
    "Here, *raw* refers to provider metadata, that has not yet been transformed into the CAMELS-de Metadata schema."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, Brandenburg is quite cool. This will be hard to parse. Let's first extract the big Zip, because it's a zip of Excel, with MANY sheets. To make thing more complicated, they splitted the Excel files into two files, I guess because they got too large (haha)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the ZIP in place\n",
    "if not os.path.exists(os.path.join(BASE, 'Q.TagWerte_1.xlsx')):\n",
    "    with zipfile.ZipFile(os.path.join(BASE, 'Anlage_4_W_Q-TagWerte.zip')) as z:\n",
    "        for f in z.filelist:\n",
    "            z.extract(f, BASE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the metadata from each sheet, for this, first read in all files and create a mapping from station ids to the sheet in the respective excel_file. \n",
    "\n",
    "Ah, nice, why call them by their name if you can just call them 'Zeitreihe_1', 'Zeitreihe_2' and so on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = pd.ExcelFile(os.path.join(BASE, 'Q.TagWerte_1.xlsx'))\n",
    "q2 = pd.ExcelFile(os.path.join(BASE, 'Q.TagWerte_2.xlsx'))\n",
    "w1 = pd.ExcelFile(os.path.join(BASE, 'W.TagWerte_1.xlsx'))\n",
    "w2 = pd.ExcelFile(os.path.join(BASE, 'W.TagWerte_2.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Name</td>\n",
       "      <td>Alt Ruppin, Schleuse OP.Q.TagWerte</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID</td>\n",
       "      <td>165666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parameter</td>\n",
       "      <td>Durchfluss</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Einheit</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anzahl Messwerte</td>\n",
       "      <td>15327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15348</th>\n",
       "      <td>2022-10-14 00:00:00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>131072</td>\n",
       "      <td>Ungeprüft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15349</th>\n",
       "      <td>2022-10-15 00:00:00</td>\n",
       "      <td>1.22</td>\n",
       "      <td>131072</td>\n",
       "      <td>Ungeprüft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15350</th>\n",
       "      <td>2022-10-16 00:00:00</td>\n",
       "      <td>1.21</td>\n",
       "      <td>131072</td>\n",
       "      <td>Ungeprüft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15351</th>\n",
       "      <td>2022-10-17 00:00:00</td>\n",
       "      <td>1.2</td>\n",
       "      <td>131072</td>\n",
       "      <td>Ungeprüft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15352</th>\n",
       "      <td>2022-10-18 00:00:00</td>\n",
       "      <td>1.19</td>\n",
       "      <td>131072</td>\n",
       "      <td>Ungeprüft</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15353 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0                                   1       2  \\\n",
       "0                     Name  Alt Ruppin, Schleuse OP.Q.TagWerte     NaN   \n",
       "1                       ID                              165666     NaN   \n",
       "2                Parameter                          Durchfluss     NaN   \n",
       "3                  Einheit                                m³/s     NaN   \n",
       "4         Anzahl Messwerte                               15327     NaN   \n",
       "...                    ...                                 ...     ...   \n",
       "15348  2022-10-14 00:00:00                                 1.2  131072   \n",
       "15349  2022-10-15 00:00:00                                1.22  131072   \n",
       "15350  2022-10-16 00:00:00                                1.21  131072   \n",
       "15351  2022-10-17 00:00:00                                 1.2  131072   \n",
       "15352  2022-10-18 00:00:00                                1.19  131072   \n",
       "\n",
       "               3  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "...          ...  \n",
       "15348  Ungeprüft  \n",
       "15349  Ungeprüft  \n",
       "15350  Ungeprüft  \n",
       "15351  Ungeprüft  \n",
       "15352  Ungeprüft  \n",
       "\n",
       "[15353 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'Zeitreihe_1'\n",
    "df = q1.parse(name, header=None, usecols=[0,1,2,3])\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be a tough sunday.\n",
    "\n",
    "The header is changing its size. I hope the blocks stay the same..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Name': 'Alt Ruppin, Schleuse OP.Q.TagWerte',\n",
       "  'ID': '165666',\n",
       "  'Parameter': 'Durchfluss',\n",
       "  'Einheit': 'm³/s',\n",
       "  'Anzahl Messwerte': '15327',\n",
       "  'Messwerte von': '01.11.1980 00:00:00',\n",
       "  'Messwerte bis': '18.10.2022 00:00:00',\n",
       "  'Name vom Messort/ Messgebiet': 'Alt Ruppin, Schleuse OP, 5891200',\n",
       "  'Pegelname': 'Alt Ruppin, Schleuse OP',\n",
       "  'Gewaesser': 'Rhin (Ruppiner Wasserstraße)',\n",
       "  'Status': 'Aktuell',\n",
       "  'Betreiber': 'LfU Brandenburg',\n",
       "  'PNP_Höhenstatus': 'DHHN2016',\n",
       "  'PNP_Höhe': '34.965',\n",
       "  'Fluss_KM': '49.901',\n",
       "  'FlussohMdg': '45.42',\n",
       "  'Gew_Kennz': '588',\n",
       "  'Meldewesen': 'täglicher Meldedienst',\n",
       "  'Pegelklasse': 'Gewässerkundliches Netz (GK)',\n",
       "  'Messstellennummer': '5891200',\n",
       "  'CRS': 'UTM 33N',\n",
       "  'Ost/RW': '354590.00',\n",
       "  'Nord/HW': '5869955.00'},\n",
       "              date     q   flag\n",
       " 26     1980-11-01  2.20   True\n",
       " 27     1980-11-02  2.20   True\n",
       " 28     1980-11-03  2.20   True\n",
       " 29     1980-11-04  2.20   True\n",
       " 30     1980-11-05  2.20   True\n",
       " ...           ...   ...    ...\n",
       " 15348  2022-10-14  1.20  False\n",
       " 15349  2022-10-15  1.22  False\n",
       " 15350  2022-10-16  1.21  False\n",
       " 15351  2022-10-17  1.20  False\n",
       " 15352  2022-10-18  1.19  False\n",
       " \n",
       " [15327 rows x 3 columns])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_dirty_dataframe(df: pd.DataFrame, variable: str, skip_data: bool = False) -> Tuple[Dict, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Parse the dirty dataframe directly read from the excel sheets.\n",
    "\n",
    "    \"\"\"\n",
    "    # get all empty row, as they separate the block, of course\n",
    "    null_idx = df[df.isnull().all(axis=1) == True].index.to_list()\n",
    "\n",
    "    # mark all block as None for now\n",
    "    ID = None\n",
    "    base = {}\n",
    "    loc = {}\n",
    "    co = {}\n",
    "    dat = None\n",
    "\n",
    "    # We expect three blocks here, base metadata, location metadata, coordinates and data\n",
    "    for i, (lo, up) in enumerate(zip([0] + null_idx, null_idx + [len(df)])):\n",
    "        # extract the block\n",
    "        block = df.iloc[lo:up, :]\n",
    "        \n",
    "        # switch the block\n",
    "        # data block - skipping for now\n",
    "        if i == 3 and not skip_data:\n",
    "            # on i==0, the ID should be filled, otherwise we have to handcraft this data\n",
    "            if ID is None:\n",
    "                continue\n",
    "            \n",
    "            # get the block\n",
    "            block = block.dropna(axis=0, how='all').dropna(axis=1, how='all')\n",
    "\n",
    "            # set the header\n",
    "            block.columns = block.iloc[0, :]\n",
    "            block.drop(block.index[0], axis=0, inplace=True)\n",
    "\n",
    "            # transform the data as everything is string, of course\n",
    "            dat = pd.DataFrame({\n",
    "                'date': [d.date() if isinstance(d, dt) else parse(d) for d in block.iloc[:, 0].values],\n",
    "                variable.lower(): block.iloc[:, 1].astype(float),\n",
    "                'flag': [fl.strip().lower() == 'geprüft' for fl in block.iloc[:, 3].values]\n",
    "            })\n",
    "        \n",
    "        # base data or Standord\n",
    "        if i == 0 or i == 1:\n",
    "            block = block.iloc[:, :2].dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "            block = block.set_index(0).T.to_dict(orient='records')\n",
    "            if len(block) > 0:\n",
    "                if i == 0:\n",
    "                    if 'ID' in block[0].keys():\n",
    "                        ID = str(block[0]['ID'])\n",
    "                    else:\n",
    "                        warnings.warn(f\"Block #{i + 1}: No ID found. This will skip the data for this station.\")\n",
    "                    base = block[0]\n",
    "                else:\n",
    "                    loc = block[0]\n",
    "            else:\n",
    "                warnings.warn(f\"Block #{i + 1}: did not yield the correct shape. Please check the file. Skipping.\")\n",
    "        \n",
    "        # Koordinaten\n",
    "        elif i == 2:\n",
    "            # drop NaNs on both axis\n",
    "            block = block.dropna(axis=1, how='all').dropna(axis=0, how='all')\n",
    "            \n",
    "            # rename the CRS header\n",
    "            block.iloc[0, 0] = 'CRS'\n",
    "            block.columns = block.iloc[0]\n",
    "            block.drop(block.index[0], axis=0, inplace=True)\n",
    "            block = block.to_dict(orient='records')\n",
    "\n",
    "            if len(block) > 0:\n",
    "                co = block[0]\n",
    "            else:\n",
    "                warnings.warn(f\"Block #{i + 1} did not yield the correct shape. Please check the file. Skipping.\")\n",
    "\n",
    "    # now merge the metadata\n",
    "    meta = {**base, **loc, **co}\n",
    "\n",
    "    # if there was no metadata, set meta None again\n",
    "    if len(meta.keys()) == 0:\n",
    "        meta = None\n",
    "    \n",
    "    # finally return all we got\n",
    "    return meta, dat\n",
    "\n",
    "\n",
    "# Test the stuff\n",
    "parse_dirty_dataframe(df, 'q', skip_data=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate metadata and data in Memory\n",
    "\n",
    "I hope all the stuff can be put into Memory at once, otherwise we have to chunk it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:34<00:00,  1.54s/it]\n",
      "100%|██████████| 67/67 [00:52<00:00,  1.27it/s]\n",
      "100%|██████████| 100/100 [01:21<00:00,  1.22it/s]\n",
      "100%|██████████| 115/115 [01:23<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata length: 382    data files: 382      warnings:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# empty container for the data\n",
    "metadata, data, warns = [], [], []\n",
    "\n",
    "with warnings.catch_warnings(record=True) as wa:\n",
    "    # extract from each of the four excel sheets\n",
    "    for variable, xls in zip(('q', 'q', 'w', 'w'), (q1, q2, w1, w2)):\n",
    "        # go for each sheet\n",
    "        for sheet_name in tqdm(xls.sheet_names):\n",
    "            # load the dirty sheet\n",
    "            df = xls.parse(sheet_name, header=None, usecols=[0,1,2,3])\n",
    "\n",
    "            # parse it\n",
    "            meta, dat = parse_dirty_dataframe(df, variable)\n",
    "\n",
    "            if meta is not None:\n",
    "                metadata.append(meta),\n",
    "                data.append(dat)\n",
    "\n",
    "    # copy warnings\n",
    "    warns.extend(wa)\n",
    "\n",
    "print(f\"metadata length: {len(metadata)}    data files: {len(data)}      warnings:{len(warns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>w</th>\n",
       "      <th>w_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1977-11-01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1977-11-02</td>\n",
       "      <td>36.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1977-11-03</td>\n",
       "      <td>42.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1977-11-04</td>\n",
       "      <td>42.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1977-11-05</td>\n",
       "      <td>42.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16444</th>\n",
       "      <td>2022-10-13</td>\n",
       "      <td>75.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16445</th>\n",
       "      <td>2022-10-14</td>\n",
       "      <td>75.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16446</th>\n",
       "      <td>2022-10-15</td>\n",
       "      <td>76.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16447</th>\n",
       "      <td>2022-10-16</td>\n",
       "      <td>75.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16448</th>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>75.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16420 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date     w  w_flag\n",
       "29     1977-11-01  36.0    True\n",
       "30     1977-11-02  36.0    True\n",
       "31     1977-11-03  42.0    True\n",
       "32     1977-11-04  42.0    True\n",
       "33     1977-11-05  42.0    True\n",
       "...           ...   ...     ...\n",
       "16444  2022-10-13  75.0   False\n",
       "16445  2022-10-14  75.0   False\n",
       "16446  2022-10-15  76.0   False\n",
       "16447  2022-10-16  75.0   False\n",
       "16448  2022-10-17  75.0   False\n",
       "\n",
       "[16420 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There is more\n",
    "\n",
    "We have not only Anlage 4, but also Anlage 3. Check this file out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlapping names: False\n",
      "Overlapping Messstellennummer: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/anaconda3/lib/python3.9/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    }
   ],
   "source": [
    "# define the function \n",
    "def read_meta(base_path) -> pd.DataFrame:\n",
    "    path = os.path.join(base_path, 'Anlage_3.xlsx')\n",
    "    meta = pd.read_excel(path)\n",
    "    return meta\n",
    "\n",
    "# test it here\n",
    "other_meta = read_meta(BASE)\n",
    "pmeta = pd.DataFrame(metadata)\n",
    "\n",
    "# merge with the other, more interesting metadata\n",
    "#meta = pd.merge(pd.DataFrame(metadata), other_meta, left_on='ID', right_on='station_no', how='inner')\n",
    "\n",
    "print(f\"Overlapping names: {any([n in pmeta.Name.values for n in other_meta.station_name])}\")\n",
    "print(f\"Overlapping Messstellennummer: {any([str(i) in pmeta.Messstellennummer.values.tolist() for i in other_meta.station_no])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>ID</th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Einheit</th>\n",
       "      <th>Anzahl Messwerte</th>\n",
       "      <th>Messwerte von</th>\n",
       "      <th>Messwerte bis</th>\n",
       "      <th>Name vom Messort/ Messgebiet</th>\n",
       "      <th>Pegelname</th>\n",
       "      <th>Gewaesser</th>\n",
       "      <th>...</th>\n",
       "      <th>Messstellennummer</th>\n",
       "      <th>CRS</th>\n",
       "      <th>Ost/RW</th>\n",
       "      <th>Nord/HW</th>\n",
       "      <th>W_seit</th>\n",
       "      <th>W_bis</th>\n",
       "      <th>Q_seit</th>\n",
       "      <th>station_name</th>\n",
       "      <th>CATCHMENT_SIZE</th>\n",
       "      <th>BODY_RESPONSIBLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alt Ruppin, Schleuse OP.Q.TagWerte</td>\n",
       "      <td>165666</td>\n",
       "      <td>Durchfluss</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>15327</td>\n",
       "      <td>01.11.1980 00:00:00</td>\n",
       "      <td>18.10.2022 00:00:00</td>\n",
       "      <td>Alt Ruppin, Schleuse OP, 5891200</td>\n",
       "      <td>Alt Ruppin, Schleuse OP</td>\n",
       "      <td>Rhin (Ruppiner Wasserstraße)</td>\n",
       "      <td>...</td>\n",
       "      <td>5891200</td>\n",
       "      <td>UTM 33N</td>\n",
       "      <td>354590.00</td>\n",
       "      <td>5869955.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alt Ruppin, Schleuse OP</td>\n",
       "      <td>533,24 km²</td>\n",
       "      <td>LfU Brandenburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Altlandsberg 2, Walkmühle.Q.TagWerte</td>\n",
       "      <td>278150</td>\n",
       "      <td>Durchfluss</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>11990</td>\n",
       "      <td>01.11.1987 00:00:00</td>\n",
       "      <td>31.08.2022 00:00:00</td>\n",
       "      <td>Altlandsberg 2, Walkmühle, 5861002</td>\n",
       "      <td>Altlandsberg 2, Walkmühle</td>\n",
       "      <td>Erpe/Neuenhagener Fließ</td>\n",
       "      <td>...</td>\n",
       "      <td>5861002</td>\n",
       "      <td>UTM 33N</td>\n",
       "      <td>413345.00</td>\n",
       "      <td>5825130.00</td>\n",
       "      <td>24.08.1987</td>\n",
       "      <td>aktuell</td>\n",
       "      <td>01.11.1987</td>\n",
       "      <td>Altlandsberg 2, Walkmühle</td>\n",
       "      <td>118,21 km²</td>\n",
       "      <td>LfU Brandenburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Babelsberg-Drewitz.Q.TagWerte</td>\n",
       "      <td>166379</td>\n",
       "      <td>Durchfluss</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>24824</td>\n",
       "      <td>01.11.1954 00:00:00</td>\n",
       "      <td>18.10.2022 00:00:00</td>\n",
       "      <td>Babelsberg-Drewitz, 5871600</td>\n",
       "      <td>Babelsberg-Drewitz</td>\n",
       "      <td>Nuthe</td>\n",
       "      <td>...</td>\n",
       "      <td>5871600</td>\n",
       "      <td>UTM 33N</td>\n",
       "      <td>371737.00</td>\n",
       "      <td>5803058.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Babelsberg-Drewitz</td>\n",
       "      <td>1792,07 km²</td>\n",
       "      <td>LfU Brandenburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bad Liebenwerda.Q.TagWerte</td>\n",
       "      <td>166369</td>\n",
       "      <td>Durchfluss</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>23364</td>\n",
       "      <td>01.11.1960 00:00:00</td>\n",
       "      <td>19.10.2022 00:00:00</td>\n",
       "      <td>Bad Liebenwerda, 5530500</td>\n",
       "      <td>Bad Liebenwerda</td>\n",
       "      <td>Schwarze Elster</td>\n",
       "      <td>...</td>\n",
       "      <td>5530500</td>\n",
       "      <td>UTM 33N</td>\n",
       "      <td>388602.00</td>\n",
       "      <td>5708769.00</td>\n",
       "      <td>01.12.1887</td>\n",
       "      <td>aktuell</td>\n",
       "      <td>01.11.1920</td>\n",
       "      <td>Bad Liebenwerda</td>\n",
       "      <td>3154,03 km²</td>\n",
       "      <td>LfU Brandenburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bad Wilsnack.Q.TagWerte</td>\n",
       "      <td>165980</td>\n",
       "      <td>Durchfluss</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>16056</td>\n",
       "      <td>01.11.1975 00:00:00</td>\n",
       "      <td>16.10.2022 00:00:00</td>\n",
       "      <td>Bad Wilsnack, 5930500</td>\n",
       "      <td>Bad Wilsnack</td>\n",
       "      <td>Karthane</td>\n",
       "      <td>...</td>\n",
       "      <td>5930500</td>\n",
       "      <td>UTM 33N</td>\n",
       "      <td>294280.00</td>\n",
       "      <td>5871815.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bad Wilsnack</td>\n",
       "      <td>284,62 km²</td>\n",
       "      <td>LfU Brandenburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>Wünsdorf 1 UP.W.TagWerte</td>\n",
       "      <td>301037</td>\n",
       "      <td>Wasserstand</td>\n",
       "      <td>cm</td>\n",
       "      <td>14184</td>\n",
       "      <td>01.11.1983 00:00:00</td>\n",
       "      <td>31.08.2022 00:00:00</td>\n",
       "      <td>Wünsdorf 1 UP, 5865501</td>\n",
       "      <td>Wünsdorf 1 UP</td>\n",
       "      <td>Wünsdorfer Kanal</td>\n",
       "      <td>...</td>\n",
       "      <td>5865501</td>\n",
       "      <td>UTM 33N</td>\n",
       "      <td>393811.00</td>\n",
       "      <td>5778777.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.05.1983</td>\n",
       "      <td>17.05.1983</td>\n",
       "      <td>Wünsdorf 1 UP</td>\n",
       "      <td>47,31 km²</td>\n",
       "      <td>LfU Brandenburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Wünsdorf 2 OP.W.TagWerte</td>\n",
       "      <td>301044</td>\n",
       "      <td>Wasserstand</td>\n",
       "      <td>cm</td>\n",
       "      <td>19191</td>\n",
       "      <td>01.11.1969 00:00:00</td>\n",
       "      <td>31.08.2022 00:00:00</td>\n",
       "      <td>Wünsdorf 2 OP, 5865600</td>\n",
       "      <td>Wünsdorf 2 OP</td>\n",
       "      <td>Neuer Graben</td>\n",
       "      <td>...</td>\n",
       "      <td>5865600</td>\n",
       "      <td>UTM 33N</td>\n",
       "      <td>394693.00</td>\n",
       "      <td>5779961.00</td>\n",
       "      <td>01.08.1969</td>\n",
       "      <td>aktuell</td>\n",
       "      <td>01.08.1969</td>\n",
       "      <td>Wünsdorf 2 OP</td>\n",
       "      <td>0,04 km²</td>\n",
       "      <td>LfU Brandenburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>Wünsdorf.W.TagWerte</td>\n",
       "      <td>301055</td>\n",
       "      <td>Wasserstand</td>\n",
       "      <td>cm</td>\n",
       "      <td>14183</td>\n",
       "      <td>01.11.1983 00:00:00</td>\n",
       "      <td>31.08.2022 00:00:00</td>\n",
       "      <td>Wünsdorf, 5865502</td>\n",
       "      <td>Wünsdorf</td>\n",
       "      <td>Luchgraben</td>\n",
       "      <td>...</td>\n",
       "      <td>5865502</td>\n",
       "      <td>UTM 33N</td>\n",
       "      <td>393821.00</td>\n",
       "      <td>5778750.00</td>\n",
       "      <td>17.05.1983</td>\n",
       "      <td>aktuell</td>\n",
       "      <td>17.05.1983</td>\n",
       "      <td>Wünsdorf</td>\n",
       "      <td>47,31 km²</td>\n",
       "      <td>LfU Brandenburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Zeuthen, Straßenbrücke.W.TagWerte</td>\n",
       "      <td>301061</td>\n",
       "      <td>Wasserstand</td>\n",
       "      <td>cm</td>\n",
       "      <td>17123</td>\n",
       "      <td>01.11.1975 00:00:00</td>\n",
       "      <td>17.10.2022 00:00:00</td>\n",
       "      <td>Zeuthen, Straßenbrücke, 5865900</td>\n",
       "      <td>Zeuthen, Straßenbrücke</td>\n",
       "      <td>Selchower Flutgraben</td>\n",
       "      <td>...</td>\n",
       "      <td>5865900</td>\n",
       "      <td>UTM 33N</td>\n",
       "      <td>406492.00</td>\n",
       "      <td>5801049.00</td>\n",
       "      <td>09.06.1975</td>\n",
       "      <td>aktuell</td>\n",
       "      <td>01.11.1975</td>\n",
       "      <td>Zeuthen, Straßenbrücke</td>\n",
       "      <td>76,01 km²</td>\n",
       "      <td>LfU Brandenburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Zschorno.W.TagWerte</td>\n",
       "      <td>277775</td>\n",
       "      <td>Wasserstand</td>\n",
       "      <td>cm</td>\n",
       "      <td>16420</td>\n",
       "      <td>01.11.1977 00:00:00</td>\n",
       "      <td>17.10.2022 00:00:00</td>\n",
       "      <td>Zschorno, 6650100</td>\n",
       "      <td>Zschorno</td>\n",
       "      <td>Föhrenfließ/Lachgraben</td>\n",
       "      <td>...</td>\n",
       "      <td>6650100</td>\n",
       "      <td>UTM 33N</td>\n",
       "      <td>479160.00</td>\n",
       "      <td>5714011.00</td>\n",
       "      <td>01.11.1977</td>\n",
       "      <td>aktuell</td>\n",
       "      <td>01.11.1977</td>\n",
       "      <td>Zschorno</td>\n",
       "      <td>75,62 km²</td>\n",
       "      <td>LfU Brandenburg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>382 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Name      ID    Parameter Einheit  \\\n",
       "0      Alt Ruppin, Schleuse OP.Q.TagWerte  165666   Durchfluss    m³/s   \n",
       "1    Altlandsberg 2, Walkmühle.Q.TagWerte  278150   Durchfluss    m³/s   \n",
       "2           Babelsberg-Drewitz.Q.TagWerte  166379   Durchfluss    m³/s   \n",
       "3              Bad Liebenwerda.Q.TagWerte  166369   Durchfluss    m³/s   \n",
       "4                 Bad Wilsnack.Q.TagWerte  165980   Durchfluss    m³/s   \n",
       "..                                    ...     ...          ...     ...   \n",
       "377              Wünsdorf 1 UP.W.TagWerte  301037  Wasserstand      cm   \n",
       "378              Wünsdorf 2 OP.W.TagWerte  301044  Wasserstand      cm   \n",
       "379                   Wünsdorf.W.TagWerte  301055  Wasserstand      cm   \n",
       "380     Zeuthen, Straßenbrücke.W.TagWerte  301061  Wasserstand      cm   \n",
       "381                   Zschorno.W.TagWerte  277775  Wasserstand      cm   \n",
       "\n",
       "    Anzahl Messwerte        Messwerte von        Messwerte bis  \\\n",
       "0              15327  01.11.1980 00:00:00  18.10.2022 00:00:00   \n",
       "1              11990  01.11.1987 00:00:00  31.08.2022 00:00:00   \n",
       "2              24824  01.11.1954 00:00:00  18.10.2022 00:00:00   \n",
       "3              23364  01.11.1960 00:00:00  19.10.2022 00:00:00   \n",
       "4              16056  01.11.1975 00:00:00  16.10.2022 00:00:00   \n",
       "..               ...                  ...                  ...   \n",
       "377            14184  01.11.1983 00:00:00  31.08.2022 00:00:00   \n",
       "378            19191  01.11.1969 00:00:00  31.08.2022 00:00:00   \n",
       "379            14183  01.11.1983 00:00:00  31.08.2022 00:00:00   \n",
       "380            17123  01.11.1975 00:00:00  17.10.2022 00:00:00   \n",
       "381            16420  01.11.1977 00:00:00  17.10.2022 00:00:00   \n",
       "\n",
       "           Name vom Messort/ Messgebiet                  Pegelname  \\\n",
       "0      Alt Ruppin, Schleuse OP, 5891200    Alt Ruppin, Schleuse OP   \n",
       "1    Altlandsberg 2, Walkmühle, 5861002  Altlandsberg 2, Walkmühle   \n",
       "2           Babelsberg-Drewitz, 5871600         Babelsberg-Drewitz   \n",
       "3              Bad Liebenwerda, 5530500            Bad Liebenwerda   \n",
       "4                 Bad Wilsnack, 5930500               Bad Wilsnack   \n",
       "..                                  ...                        ...   \n",
       "377              Wünsdorf 1 UP, 5865501              Wünsdorf 1 UP   \n",
       "378              Wünsdorf 2 OP, 5865600              Wünsdorf 2 OP   \n",
       "379                   Wünsdorf, 5865502                   Wünsdorf   \n",
       "380     Zeuthen, Straßenbrücke, 5865900     Zeuthen, Straßenbrücke   \n",
       "381                   Zschorno, 6650100                   Zschorno   \n",
       "\n",
       "                        Gewaesser  ... Messstellennummer      CRS     Ost/RW  \\\n",
       "0    Rhin (Ruppiner Wasserstraße)  ...           5891200  UTM 33N  354590.00   \n",
       "1         Erpe/Neuenhagener Fließ  ...           5861002  UTM 33N  413345.00   \n",
       "2                           Nuthe  ...           5871600  UTM 33N  371737.00   \n",
       "3                 Schwarze Elster  ...           5530500  UTM 33N  388602.00   \n",
       "4                        Karthane  ...           5930500  UTM 33N  294280.00   \n",
       "..                            ...  ...               ...      ...        ...   \n",
       "377              Wünsdorfer Kanal  ...           5865501  UTM 33N  393811.00   \n",
       "378                  Neuer Graben  ...           5865600  UTM 33N  394693.00   \n",
       "379                    Luchgraben  ...           5865502  UTM 33N  393821.00   \n",
       "380          Selchower Flutgraben  ...           5865900  UTM 33N  406492.00   \n",
       "381        Föhrenfließ/Lachgraben  ...           6650100  UTM 33N  479160.00   \n",
       "\n",
       "        Nord/HW      W_seit       W_bis      Q_seit  \\\n",
       "0    5869955.00         NaN         NaN         NaN   \n",
       "1    5825130.00  24.08.1987     aktuell  01.11.1987   \n",
       "2    5803058.00         NaN         NaN         NaN   \n",
       "3    5708769.00  01.12.1887     aktuell  01.11.1920   \n",
       "4    5871815.00         NaN         NaN         NaN   \n",
       "..          ...         ...         ...         ...   \n",
       "377  5778777.00         NaN  17.05.1983  17.05.1983   \n",
       "378  5779961.00  01.08.1969     aktuell  01.08.1969   \n",
       "379  5778750.00  17.05.1983     aktuell  17.05.1983   \n",
       "380  5801049.00  09.06.1975     aktuell  01.11.1975   \n",
       "381  5714011.00  01.11.1977     aktuell  01.11.1977   \n",
       "\n",
       "                  station_name CATCHMENT_SIZE BODY_RESPONSIBLE  \n",
       "0      Alt Ruppin, Schleuse OP     533,24 km²  LfU Brandenburg  \n",
       "1    Altlandsberg 2, Walkmühle     118,21 km²  LfU Brandenburg  \n",
       "2           Babelsberg-Drewitz    1792,07 km²  LfU Brandenburg  \n",
       "3              Bad Liebenwerda    3154,03 km²  LfU Brandenburg  \n",
       "4                 Bad Wilsnack     284,62 km²  LfU Brandenburg  \n",
       "..                         ...            ...              ...  \n",
       "377              Wünsdorf 1 UP      47,31 km²  LfU Brandenburg  \n",
       "378              Wünsdorf 2 OP       0,04 km²  LfU Brandenburg  \n",
       "379                   Wünsdorf      47,31 km²  LfU Brandenburg  \n",
       "380     Zeuthen, Straßenbrücke      76,01 km²  LfU Brandenburg  \n",
       "381                   Zschorno      75,62 km²  LfU Brandenburg  \n",
       "\n",
       "[382 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join both metadata together\n",
    "all_meta = pmeta.join(other_meta.set_index('station_no'), on='Messstellennummer', how='left')\n",
    "all_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the id column will be Messstellennummer\n",
    "id_column = 'ID'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that we have an ID everywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All stations have an id: True\n",
      "Any duplicated IDs:      False\n"
     ]
    }
   ],
   "source": [
    "print(f\"All stations have an id: {all(['ID' in m for m in metadata])}\")\n",
    "print(f\"Any duplicated IDs:      {pd.DataFrame(metadata).ID.duplicated().any()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally run\n",
    "\n",
    "Save the stuff using the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nuts_id provider_id                              path\n",
      "0  DE410000      165666  ./DE4/DE410000/DE410000_data.csv\n",
      "1  DE410010      278150  ./DE4/DE410010/DE410010_data.csv\n",
      "2  DE410020      166379  ./DE4/DE410020/DE410020_data.csv\n",
      "3  DE410030      166369  ./DE4/DE410030/DE410030_data.csv\n",
      "4  DE410040      165980  ./DE4/DE410040/DE410040_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/382 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 382/382 [00:20<00:00, 18.28it/s]\n"
     ]
    }
   ],
   "source": [
    "with Bundesland('Brandenburg') as bl:\n",
    "    # save the metadata\n",
    "    bl.save_raw_metadata(all_meta, id_column, overwrite=True)\n",
    "\n",
    "    # for reference, call the nuts-mapping as table\n",
    "    nuts_map = bl.nuts_table\n",
    "    print(nuts_map.head())\n",
    "    \n",
    "    # go for each of the files\n",
    "    for station_meta, station_data in tqdm(zip(metadata, data), total=len(metadata)):\n",
    "        # get the provider id\n",
    "        provider_id = station_meta[id_column]\n",
    "        \n",
    "        # save\n",
    "        bl.save_timeseries(station_data, provider_id)\n",
    "\n",
    "    # check if there were warnings (there are warnings)\n",
    "    if len(warns) > 0:\n",
    "        log_path = bl.save_warnings(warns)\n",
    "        print(f\"There were warnings during the processing. The log can be found at: {log_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>w</th>\n",
       "      <th>w_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1977-11-01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1977-11-02</td>\n",
       "      <td>36.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1977-11-03</td>\n",
       "      <td>42.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1977-11-04</td>\n",
       "      <td>42.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1977-11-05</td>\n",
       "      <td>42.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16444</th>\n",
       "      <td>2022-10-13</td>\n",
       "      <td>75.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16445</th>\n",
       "      <td>2022-10-14</td>\n",
       "      <td>75.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16446</th>\n",
       "      <td>2022-10-15</td>\n",
       "      <td>76.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16447</th>\n",
       "      <td>2022-10-16</td>\n",
       "      <td>75.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16448</th>\n",
       "      <td>2022-10-17</td>\n",
       "      <td>75.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16420 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date     w  w_flag\n",
       "29     1977-11-01  36.0    True\n",
       "30     1977-11-02  36.0    True\n",
       "31     1977-11-03  42.0    True\n",
       "32     1977-11-04  42.0    True\n",
       "33     1977-11-05  42.0    True\n",
       "...           ...   ...     ...\n",
       "16444  2022-10-13  75.0   False\n",
       "16445  2022-10-14  75.0   False\n",
       "16446  2022-10-15  76.0   False\n",
       "16447  2022-10-16  75.0   False\n",
       "16448  2022-10-17  75.0   False\n",
       "\n",
       "[16420 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f54d8176e82297fa872ac8c77277e50c0e193f921954c1c4a0b1ae2e8be99b71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
