{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saarland\n",
    "\n",
    "Every federal state is represented by its own input directory and is processed into a NUTS level 2 directory containing a sub-folder for each discharge location. These folder names are derived from NUTS and reflect the CAMELS id. The NUTS level 2 code for Saarland is `DEC`.\n",
    "\n",
    "To pre-process the data, you need to write (at least) two functions. One should extract all metadata and condense it into a single `pandas.DataFrame`. This is used to build the folder structure and derive the ids.\n",
    "The second function has to take an id, as provided by the state authorities, called `provider_id` and return a `pandas.DataFrame` with the transformed data. The dataframe needs the three columns `['date', 'q' | 'w', 'flag']`.\n",
    "\n",
    "For easier and unified output handling, the `camelsp` package contains a context object called `Bundesland`. It takes a number of names and abbreviations to identify the correct federal state and returns an object that holds helper and save functions.\n",
    "\n",
    "The context saves files as needed and can easily be changed to save files with different strategies, ie. fill missing data with NaN, merge data into a single file, create files for each variable or pack everything together into a netcdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.errors import ParserError\n",
    "import os\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from typing import Union, Dict\n",
    "from datetime import datetime as dt\n",
    "from dateparser import parse\n",
    "import warnings\n",
    "\n",
    "from camelsp import Bundesland"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The context can also be instantiated as any regular Python class, ie. to load only the default input data path, that we will user later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alexander/Github/camels/camelsp/input_data/SL_Saarland'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the context also makes the input path available, if camelsp was install locally\n",
    "BASE = Bundesland('saarland').input_path\n",
    "BASE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata reader\n",
    "\n",
    "Define the function that extracts / reads and eventually merges all metadata for this federal state. You can develop the function here, without using the Bundesland context and then later use the context to pass extracted metadata. The Context has a function for saving *raw* metadata, that takes a `pandas.DataFrame` and needs you to identify the id column.\n",
    "Here, *raw* refers to provider metadata, that has not yet been transformed into the CAMELS-de Metadata schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSTNR</th>\n",
       "      <th>MSTBEM</th>\n",
       "      <th>Pegelname_</th>\n",
       "      <th>Gewässer</th>\n",
       "      <th>Betreiber</th>\n",
       "      <th>Stromgebiet</th>\n",
       "      <th>GebkNR</th>\n",
       "      <th>EZG_Gr</th>\n",
       "      <th>Flusskm</th>\n",
       "      <th>PNP</th>\n",
       "      <th>RW</th>\n",
       "      <th>HW</th>\n",
       "      <th>HWMH_1</th>\n",
       "      <th>HWMH_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1271120</td>\n",
       "      <td>Schieferstollen</td>\n",
       "      <td>Schieferstollen</td>\n",
       "      <td>Wadrill</td>\n",
       "      <td>LUA Saarland</td>\n",
       "      <td>Rhein/Saar/Prims/Wadrill</td>\n",
       "      <td>2646471</td>\n",
       "      <td>44,200km²</td>\n",
       "      <td>9,71 km</td>\n",
       "      <td>344,48 m über NN</td>\n",
       "      <td>2563271</td>\n",
       "      <td>5495766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1122120</td>\n",
       "      <td>Geislautern</td>\n",
       "      <td>Geislautern</td>\n",
       "      <td>Rossel</td>\n",
       "      <td>LUA Saarland</td>\n",
       "      <td>Rhein/Mosel/Saar/Rossel</td>\n",
       "      <td>2644791</td>\n",
       "      <td>203km²</td>\n",
       "      <td>3,275 km</td>\n",
       "      <td>184,38 m über NN</td>\n",
       "      <td>2560492</td>\n",
       "      <td>5455327</td>\n",
       "      <td>210 cm</td>\n",
       "      <td>250 cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1482120</td>\n",
       "      <td>Lisdorf</td>\n",
       "      <td>Lisdorf</td>\n",
       "      <td>Saar</td>\n",
       "      <td>WSA Saarbrücken</td>\n",
       "      <td>Rhein/Mosel/Saar</td>\n",
       "      <td>2645599</td>\n",
       "      <td>4671km²</td>\n",
       "      <td>65,885</td>\n",
       "      <td>173,50 m ü.NN</td>\n",
       "      <td>2555659</td>\n",
       "      <td>5462689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1251120</td>\n",
       "      <td>Gonnesweiler</td>\n",
       "      <td>Gonnesweiler</td>\n",
       "      <td>Bos</td>\n",
       "      <td>LUA Saarland</td>\n",
       "      <td>Rhein/Nahe/Bos</td>\n",
       "      <td>25411169</td>\n",
       "      <td>12,500km²</td>\n",
       "      <td>0,08 km</td>\n",
       "      <td>372,40 m über NN</td>\n",
       "      <td>2579042</td>\n",
       "      <td>5492542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1071120</td>\n",
       "      <td>Nonnweiler IV</td>\n",
       "      <td>Nonnweiler IV</td>\n",
       "      <td>Prims</td>\n",
       "      <td>LUA Saarland</td>\n",
       "      <td>Rhein/Saar/Prims</td>\n",
       "      <td>2646149</td>\n",
       "      <td>48,40km²</td>\n",
       "      <td>50,050 km</td>\n",
       "      <td>378,37 m über NN</td>\n",
       "      <td>2570340</td>\n",
       "      <td>5496980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSTNR           MSTBEM       Pegelname_ Gewässer        Betreiber  \\\n",
       "0  1271120  Schieferstollen  Schieferstollen  Wadrill     LUA Saarland   \n",
       "1  1122120      Geislautern      Geislautern   Rossel     LUA Saarland   \n",
       "2  1482120          Lisdorf          Lisdorf     Saar  WSA Saarbrücken   \n",
       "3  1251120     Gonnesweiler     Gonnesweiler      Bos     LUA Saarland   \n",
       "4  1071120    Nonnweiler IV    Nonnweiler IV    Prims     LUA Saarland   \n",
       "\n",
       "                Stromgebiet    GebkNR     EZG_Gr    Flusskm               PNP  \\\n",
       "0  Rhein/Saar/Prims/Wadrill   2646471  44,200km²    9,71 km  344,48 m über NN   \n",
       "1   Rhein/Mosel/Saar/Rossel   2644791     203km²   3,275 km  184,38 m über NN   \n",
       "2          Rhein/Mosel/Saar   2645599    4671km²     65,885     173,50 m ü.NN   \n",
       "3            Rhein/Nahe/Bos  25411169  12,500km²    0,08 km  372,40 m über NN   \n",
       "4          Rhein/Saar/Prims   2646149   48,40km²  50,050 km  378,37 m über NN   \n",
       "\n",
       "        RW       HW  HWMH_1  HWMH_2  \n",
       "0  2563271  5495766     NaN     NaN  \n",
       "1  2560492  5455327  210 cm  250 cm  \n",
       "2  2555659  5462689     NaN     NaN  \n",
       "3  2579042  5492542     NaN     NaN  \n",
       "4  2570340  5496980     NaN     NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the function \n",
    "def read_meta(base_path) -> pd.DataFrame:\n",
    "    path = os.path.join(base_path, 'Qry_Pegel-Stammdaten.xlsx')\n",
    "    meta = pd.read_excel(path)\n",
    "    return meta\n",
    "\n",
    "# test it here\n",
    "metadata = read_meta(BASE)\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the id column will be MSTNR\n",
    "id_column = 'MSTNR'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## file extract and parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>w</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-09-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-09-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-09-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-09-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3773</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3775 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date     w  flag\n",
       "0    2011-09-01   NaN   NaN\n",
       "1    2011-09-02   NaN   NaN\n",
       "2    2011-09-03   NaN   NaN\n",
       "3    2011-09-04   NaN   NaN\n",
       "4    2011-09-05   NaN   NaN\n",
       "...         ...   ...   ...\n",
       "3770 2021-12-27  33.0   NaN\n",
       "3771 2021-12-28  41.0   NaN\n",
       "3772 2021-12-29  40.0   NaN\n",
       "3773 2021-12-30  41.0   NaN\n",
       "3774 2021-12-31  33.0   NaN\n",
       "\n",
       "[3775 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the filename\n",
    "variable = 'w'\n",
    "ID = metadata.loc[55, id_column]\n",
    "\n",
    "def extract_file(ID: Union[int, str], variable: str, base_path: str) -> pd.DataFrame:\n",
    "    # use always str ids and variable is used uppercase here\n",
    "    ID = str(ID)\n",
    "    sym = variable.upper()\n",
    "\n",
    "    # build the path\n",
    "    path = os.path.join(base_path, f'TM{sym}', f\"{ID}-{sym}.TM{sym}\")\n",
    "\n",
    "    # if the files does not exist, return empty dataframe\n",
    "    if not os.path.exists(path):\n",
    "        return pd.DataFrame(columns=['date', variable.lower(), 'flag'])\n",
    "\n",
    "    # read id\n",
    "    df = pd.read_csv(path, encoding='latin1', sep='\\s+', skiprows=1, header=None, parse_dates=[0], dayfirst=True, decimal=',', na_values=[9999, -9999])\n",
    "    df.columns = ['date', variable.lower()]\n",
    "    df['flag'] = np.NaN\n",
    "\n",
    "    return df\n",
    "\n",
    "# test stuff\n",
    "extract_file(ID, variable, BASE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally run\n",
    "\n",
    "Now, the Q and W data can be extracted. The cool thing is, that all the id creation, data creation, merging and the mapping from our ids to the original ids and files is done by the context. This is helpful, as we less likely screw something up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nuts_id provider_id                              path\n",
      "0  DEC10000     1271120  ./DEC/DEC10000/DEC10000_data.csv\n",
      "1  DEC10010     1122120  ./DEC/DEC10010/DEC10010_data.csv\n",
      "2  DEC10020     1482120  ./DEC/DEC10020/DEC10020_data.csv\n",
      "3  DEC10030     1251120  ./DEC/DEC10030/DEC10030_data.csv\n",
      "4  DEC10040     1071120  ./DEC/DEC10040/DEC10040_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:04<00:00, 11.33it/s]\n"
     ]
    }
   ],
   "source": [
    "with Bundesland('Saarland') as bl:\n",
    "    # save the metadata\n",
    "    bl.save_raw_metadata(metadata, id_column, overwrite=True)\n",
    "\n",
    "    # for reference, call the nuts-mapping as table\n",
    "    nuts_map = bl.nuts_table\n",
    "    print(nuts_map.head())\n",
    "\n",
    "    \n",
    "    with warnings.catch_warnings(record=True) as warns:\n",
    "        for provider_id in tqdm(metadata[id_column].values.astype(str)):\n",
    "            \n",
    "            # get q and w\n",
    "            q_df = extract_file(provider_id, 'q', bl.input_path)\n",
    "            w_df = extract_file(provider_id, 'w', bl.input_path)\n",
    "\n",
    "            bl.save_timeseries(q_df, provider_id)\n",
    "            bl.save_timeseries(w_df, provider_id)\n",
    "\n",
    "        # check if there were warnings (there are warnings)\n",
    "        if len(warns) > 0:\n",
    "            log_path = bl.save_warnings(warns)\n",
    "            print(f\"There were warnings during the processing. The log can be found at: {log_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c57ebfed52ffd848a0d2f36f1ea9c0a9060c9b67397fbb725d6aa92a9494b08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
