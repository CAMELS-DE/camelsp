{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sachsen\n",
    "\n",
    "Every federal state is represented by its own input directory and is processed into a NUTS level 2 directory containing a sub-folder for each discharge location. These folder names are derived from NUTS and reflect the CAMELS id. The NUTS level 2 code for Sachsen is `DED`.\n",
    "\n",
    "To pre-process the data, you need to write (at least) two functions. One should extract all metadata and condense it into a single `pandas.DataFrame`. This is used to build the folder structure and derive the ids.\n",
    "The second function has to take an id, as provided by the state authorities, called `provider_id` and return a `pandas.DataFrame` with the transformed data. The dataframe needs the three columns `['date', 'q' | 'w', 'flag']`.\n",
    "\n",
    "For easier and unified output handling, the `camelsp` package contains a context object called `Bundesland`. It takes a number of names and abbreviations to identify the correct federal state and returns an object that holds helper and save functions.\n",
    "\n",
    "The context saves files as needed and can easily be changed to save files with different strategies, ie. fill missing data with NaN, merge data into a single file, create files for each variable or pack everything together into a netcdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.errors import ParserError\n",
    "import os\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from typing import Union, Dict\n",
    "from datetime import datetime as dt\n",
    "from dateparser import parse\n",
    "import warnings\n",
    "\n",
    "from camelsp import Bundesland"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The context can also be instantiated as any regular Python class, ie. to load only the default input data path, that we will user later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alexander/Github/camels/camelsp/input_data/SN_Sachsen'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the context also makes the input path available, if camelsp was install locally\n",
    "BASE = Bundesland('Sachsen').input_path\n",
    "BASE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse data\n",
    "\n",
    "We do not have a Metadata file, but one Excel file for each station. Thus we need to parse each metadata individually and collect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 282 files.\n"
     ]
    }
   ],
   "source": [
    "files = glob(os.path.join(BASE, '*.xlsx'))\n",
    "print(f\"Found {len(files)} files.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for the first file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexander/anaconda3/lib/python3.9/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pegelkennziffer: [530020]\n",
      "Pegelname:       ['Klingenthal 1']\n",
      "Gewaesser:       ['Zwota (Svatava)']\n",
      "Beeinflussung:   [nan 'R']\n",
      "Datum type:      datetime64[ns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pegelkennziffer</th>\n",
       "      <th>Pegelname</th>\n",
       "      <th>Gewaesser</th>\n",
       "      <th>Datum</th>\n",
       "      <th>Wasserstand (W) cm</th>\n",
       "      <th>Durchfluss (Q) m³/s</th>\n",
       "      <th>Beeinflussung</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>530020</td>\n",
       "      <td>Klingenthal 1</td>\n",
       "      <td>Zwota (Svatava)</td>\n",
       "      <td>1961-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.880</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>530020</td>\n",
       "      <td>Klingenthal 1</td>\n",
       "      <td>Zwota (Svatava)</td>\n",
       "      <td>1961-01-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.880</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>530020</td>\n",
       "      <td>Klingenthal 1</td>\n",
       "      <td>Zwota (Svatava)</td>\n",
       "      <td>1961-01-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.880</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>530020</td>\n",
       "      <td>Klingenthal 1</td>\n",
       "      <td>Zwota (Svatava)</td>\n",
       "      <td>1961-01-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.880</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>530020</td>\n",
       "      <td>Klingenthal 1</td>\n",
       "      <td>Zwota (Svatava)</td>\n",
       "      <td>1961-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.880</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21545</th>\n",
       "      <td>530020</td>\n",
       "      <td>Klingenthal 1</td>\n",
       "      <td>Zwota (Svatava)</td>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.070</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21546</th>\n",
       "      <td>530020</td>\n",
       "      <td>Klingenthal 1</td>\n",
       "      <td>Zwota (Svatava)</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.140</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21547</th>\n",
       "      <td>530020</td>\n",
       "      <td>Klingenthal 1</td>\n",
       "      <td>Zwota (Svatava)</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1.060</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21548</th>\n",
       "      <td>530020</td>\n",
       "      <td>Klingenthal 1</td>\n",
       "      <td>Zwota (Svatava)</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.995</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21549</th>\n",
       "      <td>530020</td>\n",
       "      <td>Klingenthal 1</td>\n",
       "      <td>Zwota (Svatava)</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.925</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21550 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pegelkennziffer      Pegelname        Gewaesser      Datum  \\\n",
       "0               530020  Klingenthal 1  Zwota (Svatava) 1961-01-01   \n",
       "1               530020  Klingenthal 1  Zwota (Svatava) 1961-01-02   \n",
       "2               530020  Klingenthal 1  Zwota (Svatava) 1961-01-03   \n",
       "3               530020  Klingenthal 1  Zwota (Svatava) 1961-01-04   \n",
       "4               530020  Klingenthal 1  Zwota (Svatava) 1961-01-05   \n",
       "...                ...            ...              ...        ...   \n",
       "21545           530020  Klingenthal 1  Zwota (Svatava) 2020-12-27   \n",
       "21546           530020  Klingenthal 1  Zwota (Svatava) 2020-12-28   \n",
       "21547           530020  Klingenthal 1  Zwota (Svatava) 2020-12-29   \n",
       "21548           530020  Klingenthal 1  Zwota (Svatava) 2020-12-30   \n",
       "21549           530020  Klingenthal 1  Zwota (Svatava) 2020-12-31   \n",
       "\n",
       "       Wasserstand (W) cm  Durchfluss (Q) m³/s Beeinflussung  \n",
       "0                     NaN                0.880           NaN  \n",
       "1                     NaN                0.880           NaN  \n",
       "2                     NaN                0.880           NaN  \n",
       "3                     NaN                0.880           NaN  \n",
       "4                     NaN                0.880           NaN  \n",
       "...                   ...                  ...           ...  \n",
       "21545                33.0                1.070           NaN  \n",
       "21546                34.0                1.140           NaN  \n",
       "21547                33.0                1.060           NaN  \n",
       "21548                32.0                0.995           NaN  \n",
       "21549                31.0                0.925           NaN  \n",
       "\n",
       "[21550 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    df = pd.read_excel(files[32], skiprows=2, decimal=',')\n",
    "\n",
    "\n",
    "print(f\"Pegelkennziffer: {df.Pegelkennziffer.unique()}\")\n",
    "print(f\"Pegelname:       {df.Pegelname.unique()}\")\n",
    "print(f\"Gewaesser:       {df.Gewaesser.unique()}\")\n",
    "print(f\"Beeinflussung:   {df.Beeinflussung.unique()}\")\n",
    "print(f\"Datum type:      {df.Datum.dtype}\")\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One question, what does Beeinflussung actually mean here? Ignoring it for now.\n",
    "\n",
    "Go for each file and extract metadata and the two data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Klingenthal 1'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df[df.columns[1]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/282 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [05:21<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 282 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create result container\n",
    "meta = []\n",
    "q = []\n",
    "w = []\n",
    "\n",
    "with warnings.catch_warnings(record=True) as warns:\n",
    "    for filename in tqdm(files):\n",
    "        # read\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            df = pd.read_excel(filename, skiprows=2, decimal=',')\n",
    "\n",
    "        # extract data columns\n",
    "        q_df = df[['Datum', 'Durchfluss (Q) m³/s']].copy()\n",
    "        q_df.columns = ['date', 'q']\n",
    "        q_df['flag'] = np.NaN\n",
    "        \n",
    "        w_df = df[['Datum', 'Wasserstand (W) cm']].copy()\n",
    "        w_df.columns = ['date', 'w']\n",
    "        w_df['flag'] = np.NaN\n",
    "        \n",
    "        # append\n",
    "        q.append(q_df)\n",
    "        w.append(w_df)\n",
    "\n",
    "        # metadata - get first three columns\n",
    "        m = dict()\n",
    "        for i in range(3):\n",
    "            # these columns need to be unique\n",
    "            if np.unique(df[df.columns[i]].values).size > 1:\n",
    "                warnings.warn(f\"Column {df.columns[i]} of file {filename} is expected to be unique\")\n",
    "                m = None\n",
    "                break\n",
    "            else:\n",
    "                # add metadata\n",
    "                m[df.columns[i]] = str(df.iloc[0, i])\n",
    "        \n",
    "        # add other stuff\n",
    "        if m is not None:     \n",
    "            m['unit_q'] = 'm³/s'\n",
    "            m['unit_w'] = 'cm'\n",
    "        meta.append(m)\n",
    "    \n",
    "print(f\"Parsed {len(meta)} files\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create metadta\n",
    "\n",
    "this should be straightforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pegelkennziffer</th>\n",
       "      <th>Pegelname</th>\n",
       "      <th>Gewaesser</th>\n",
       "      <th>unit_q</th>\n",
       "      <th>unit_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>568350</td>\n",
       "      <td>Rothenthal</td>\n",
       "      <td>Natzschung (Nacetinsky potok)</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>660001</td>\n",
       "      <td>Hartau 1</td>\n",
       "      <td>Lausitzer Neiße</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>567450</td>\n",
       "      <td>Lichtenwalde</td>\n",
       "      <td>Zschopau</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>567420</td>\n",
       "      <td>Hopfgarten</td>\n",
       "      <td>Zschopau</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>564610</td>\n",
       "      <td>Jahnsdorf</td>\n",
       "      <td>Würschnitz</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>563745</td>\n",
       "      <td>Johanngeorgenstadt 4</td>\n",
       "      <td>Schwarzwasser</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>582000</td>\n",
       "      <td>Ebersbach</td>\n",
       "      <td>Spree</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>564201</td>\n",
       "      <td>Niedermülsen 1</td>\n",
       "      <td>Mülsenbach</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>552190</td>\n",
       "      <td>Nebitzschen</td>\n",
       "      <td>Döllnitz</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>576421</td>\n",
       "      <td>Straßberg</td>\n",
       "      <td>Weiße Elster</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pegelkennziffer             Pegelname                      Gewaesser  \\\n",
       "0            568350            Rothenthal  Natzschung (Nacetinsky potok)   \n",
       "1            660001              Hartau 1                Lausitzer Neiße   \n",
       "2            567450          Lichtenwalde                       Zschopau   \n",
       "3            567420            Hopfgarten                       Zschopau   \n",
       "4            564610             Jahnsdorf                     Würschnitz   \n",
       "..              ...                   ...                            ...   \n",
       "277          563745  Johanngeorgenstadt 4                  Schwarzwasser   \n",
       "278          582000             Ebersbach                          Spree   \n",
       "279          564201        Niedermülsen 1                     Mülsenbach   \n",
       "280          552190           Nebitzschen                       Döllnitz   \n",
       "281          576421             Straßberg                   Weiße Elster   \n",
       "\n",
       "    unit_q unit_w  \n",
       "0     m³/s     cm  \n",
       "1     m³/s     cm  \n",
       "2     m³/s     cm  \n",
       "3     m³/s     cm  \n",
       "4     m³/s     cm  \n",
       "..     ...    ...  \n",
       "277   m³/s     cm  \n",
       "278   m³/s     cm  \n",
       "279   m³/s     cm  \n",
       "280   m³/s     cm  \n",
       "281   m³/s     cm  \n",
       "\n",
       "[282 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.DataFrame(meta)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = 'Pegelkennziffer'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally run\n",
    "\n",
    "Now, the Q and W data can be extracted. The cool thing is, that all the id creation, data creation, merging and the mapping from our ids to the original ids and files is done by the context. This is helpful, as we less likely screw something up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nuts_id provider_id                              path\n",
      "0  DED10000      568350  ./DED/DED10000/DED10000_data.csv\n",
      "1  DED10010      660001  ./DED/DED10010/DED10010_data.csv\n",
      "2  DED10020      567450  ./DED/DED10020/DED10020_data.csv\n",
      "3  DED10030      567420  ./DED/DED10030/DED10030_data.csv\n",
      "4  DED10040      564610  ./DED/DED10040/DED10040_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/282 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:24<00:00, 11.49it/s]\n"
     ]
    }
   ],
   "source": [
    "with Bundesland('Sachsen') as bl:\n",
    "    # save the metadata\n",
    "    bl.save_raw_metadata(metadata, id_column, overwrite=True)\n",
    "\n",
    "    # for reference, call the nuts-mapping as table\n",
    "    nuts_map = bl.nuts_table\n",
    "    print(nuts_map.head())\n",
    "\n",
    "    # go for each    \n",
    "    for m, q_df, w_df in tqdm(zip(meta, q, w), total=len(meta)):\n",
    "        \n",
    "        if m is not None:\n",
    "            # get the provider id\n",
    "            provider_id = str(m[id_column])\n",
    "            bl.save_timeseries(q_df, provider_id)\n",
    "            bl.save_timeseries(w_df, provider_id)\n",
    "\n",
    "    # check if there were warnings (there are warnings)\n",
    "    if len(warns) > 0:\n",
    "        log_path = bl.save_warnings(warns)\n",
    "        print(f\"There were warnings during the processing. The log can be found at: {log_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c57ebfed52ffd848a0d2f36f1ea9c0a9060c9b67397fbb725d6aa92a9494b08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
