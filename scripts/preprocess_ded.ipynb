{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sachsen\n",
    "\n",
    "Every federal state is represented by its own input directory and is processed into a NUTS level 2 directory containing a sub-folder for each discharge location. These folder names are derived from NUTS and reflect the CAMELS id. The NUTS level 2 code for Sachsen is `DED`.\n",
    "\n",
    "To pre-process the data, you need to write (at least) two functions. One should extract all metadata and condense it into a single `pandas.DataFrame`. This is used to build the folder structure and derive the ids.\n",
    "The second function has to take an id, as provided by the state authorities, called `provider_id` and return a `pandas.DataFrame` with the transformed data. The dataframe needs the three columns `['date', 'q' | 'w', 'flag']`.\n",
    "\n",
    "For easier and unified output handling, the `camelsp` package contains a context object called `Bundesland`. It takes a number of names and abbreviations to identify the correct federal state and returns an object that holds helper and save functions.\n",
    "\n",
    "The context saves files as needed and can easily be changed to save files with different strategies, ie. fill missing data with NaN, merge data into a single file, create files for each variable or pack everything together into a netcdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.errors import ParserError\n",
    "import os\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from typing import Union, Dict\n",
    "from datetime import datetime as dt\n",
    "from dateparser import parse\n",
    "import warnings\n",
    "\n",
    "from camelsp import Bundesland"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The context can also be instantiated as any regular Python class, ie. to load only the default input data path, that we will user later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alexd/Projekte/CAMELS/Github/camelsp/input_data/SN_Sachsen'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the context also makes the input path available, if camelsp was install locally\n",
    "BASE = Bundesland('Sachsen').input_path\n",
    "BASE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse data\n",
    "\n",
    "We do not have a Metadata file, but one Excel file for each station. Thus we need to parse each metadata individually and collect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 282 files.\n"
     ]
    }
   ],
   "source": [
    "files = glob(os.path.join(BASE, '*.xlsx'))\n",
    "print(f\"Found {len(files)} files.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for the first file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexd/miniconda3/lib/python3.11/site-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
      "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pegelkennziffer: [660193]\n",
      "Pegelname:       ['Podrosche 3']\n",
      "Gewaesser:       ['Lausitzer Neiße']\n",
      "Beeinflussung:   [nan 'b' 'e' 'R' 'R, e' 'R, T' 'b, e' 'K']\n",
      "Datum type:      datetime64[ns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pegelkennziffer</th>\n",
       "      <th>Pegelname</th>\n",
       "      <th>Gewaesser</th>\n",
       "      <th>Datum</th>\n",
       "      <th>Wasserstand (W) cm</th>\n",
       "      <th>Durchfluss (Q) m³/s</th>\n",
       "      <th>Beeinflussung</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>660193</td>\n",
       "      <td>Podrosche 3</td>\n",
       "      <td>Lausitzer Neiße</td>\n",
       "      <td>1984-11-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>660193</td>\n",
       "      <td>Podrosche 3</td>\n",
       "      <td>Lausitzer Neiße</td>\n",
       "      <td>1984-11-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>660193</td>\n",
       "      <td>Podrosche 3</td>\n",
       "      <td>Lausitzer Neiße</td>\n",
       "      <td>1984-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>660193</td>\n",
       "      <td>Podrosche 3</td>\n",
       "      <td>Lausitzer Neiße</td>\n",
       "      <td>1984-11-04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>660193</td>\n",
       "      <td>Podrosche 3</td>\n",
       "      <td>Lausitzer Neiße</td>\n",
       "      <td>1984-11-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.78</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12900</th>\n",
       "      <td>660193</td>\n",
       "      <td>Podrosche 3</td>\n",
       "      <td>Lausitzer Neiße</td>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>76.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12901</th>\n",
       "      <td>660193</td>\n",
       "      <td>Podrosche 3</td>\n",
       "      <td>Lausitzer Neiße</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>75.0</td>\n",
       "      <td>12.10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12902</th>\n",
       "      <td>660193</td>\n",
       "      <td>Podrosche 3</td>\n",
       "      <td>Lausitzer Neiße</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>71.0</td>\n",
       "      <td>11.10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12903</th>\n",
       "      <td>660193</td>\n",
       "      <td>Podrosche 3</td>\n",
       "      <td>Lausitzer Neiße</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>70.0</td>\n",
       "      <td>10.50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12904</th>\n",
       "      <td>660193</td>\n",
       "      <td>Podrosche 3</td>\n",
       "      <td>Lausitzer Neiße</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>68.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12905 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pegelkennziffer    Pegelname        Gewaesser      Datum  \\\n",
       "0               660193  Podrosche 3  Lausitzer Neiße 1984-11-01   \n",
       "1               660193  Podrosche 3  Lausitzer Neiße 1984-11-02   \n",
       "2               660193  Podrosche 3  Lausitzer Neiße 1984-11-03   \n",
       "3               660193  Podrosche 3  Lausitzer Neiße 1984-11-04   \n",
       "4               660193  Podrosche 3  Lausitzer Neiße 1984-11-05   \n",
       "...                ...          ...              ...        ...   \n",
       "12900           660193  Podrosche 3  Lausitzer Neiße 2020-12-27   \n",
       "12901           660193  Podrosche 3  Lausitzer Neiße 2020-12-28   \n",
       "12902           660193  Podrosche 3  Lausitzer Neiße 2020-12-29   \n",
       "12903           660193  Podrosche 3  Lausitzer Neiße 2020-12-30   \n",
       "12904           660193  Podrosche 3  Lausitzer Neiße 2020-12-31   \n",
       "\n",
       "       Wasserstand (W) cm  Durchfluss (Q) m³/s Beeinflussung  \n",
       "0                     NaN                 9.36           NaN  \n",
       "1                     NaN                 9.36           NaN  \n",
       "2                     NaN                 9.36           NaN  \n",
       "3                     NaN                 9.36           NaN  \n",
       "4                     NaN                 8.78           NaN  \n",
       "...                   ...                  ...           ...  \n",
       "12900                76.0                12.50           NaN  \n",
       "12901                75.0                12.10           NaN  \n",
       "12902                71.0                11.10           NaN  \n",
       "12903                70.0                10.50           NaN  \n",
       "12904                68.0                10.00           NaN  \n",
       "\n",
       "[12905 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    df = pd.read_excel(files[32], skiprows=2, decimal=',')\n",
    "\n",
    "\n",
    "print(f\"Pegelkennziffer: {df.Pegelkennziffer.unique()}\")\n",
    "print(f\"Pegelname:       {df.Pegelname.unique()}\")\n",
    "print(f\"Gewaesser:       {df.Gewaesser.unique()}\")\n",
    "print(f\"Beeinflussung:   {df.Beeinflussung.unique()}\")\n",
    "print(f\"Datum type:      {df.Datum.dtype}\")\n",
    "\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One question, what does Beeinflussung actually mean here? Ignoring it for now.\n",
    "\n",
    "Go for each file and extract metadata and the two data columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Podrosche 3'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df[df.columns[1]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [03:19<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed 282 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# create result container\n",
    "meta = []\n",
    "q = []\n",
    "w = []\n",
    "\n",
    "with warnings.catch_warnings(record=True) as warns:\n",
    "    for filename in tqdm(files):\n",
    "        # read\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            df = pd.read_excel(filename, skiprows=2, decimal=',')\n",
    "\n",
    "        # extract data columns\n",
    "        q_df = df[['Datum', 'Durchfluss (Q) m³/s']].copy()\n",
    "        q_df.columns = ['date', 'q']\n",
    "        q_df['flag'] = np.NaN\n",
    "        \n",
    "        w_df = df[['Datum', 'Wasserstand (W) cm']].copy()\n",
    "        w_df.columns = ['date', 'w']\n",
    "        w_df['flag'] = np.NaN\n",
    "        \n",
    "        # append\n",
    "        q.append(q_df)\n",
    "        w.append(w_df)\n",
    "\n",
    "        # metadata - get first three columns\n",
    "        m = dict()\n",
    "        for i in range(3):\n",
    "            # these columns need to be unique\n",
    "            if np.unique(df[df.columns[i]].values).size > 1:\n",
    "                warnings.warn(f\"Column {df.columns[i]} of file {filename} is expected to be unique\")\n",
    "                m = None\n",
    "                break\n",
    "            else:\n",
    "                # add metadata\n",
    "                m[df.columns[i]] = str(df.iloc[0, i])\n",
    "        \n",
    "        # add other stuff\n",
    "        if m is not None:     \n",
    "            m['unit_q'] = 'm³/s'\n",
    "            m['unit_w'] = 'cm'\n",
    "        meta.append(m)\n",
    "    \n",
    "print(f\"Parsed {len(meta)} files\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create metadta\n",
    "\n",
    "this should be straightforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pegelkennziffer</th>\n",
       "      <th>Pegelname</th>\n",
       "      <th>Gewaesser</th>\n",
       "      <th>unit_q</th>\n",
       "      <th>unit_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>551431</td>\n",
       "      <td>Dippoldiswalde 3</td>\n",
       "      <td>Werkgraben</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>550190</td>\n",
       "      <td>Porschdorf 1</td>\n",
       "      <td>Lachsbach</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>663090</td>\n",
       "      <td>Tauchritz</td>\n",
       "      <td>Pließnitz</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>564201</td>\n",
       "      <td>Niedermülsen 1</td>\n",
       "      <td>Mülsenbach</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>564200</td>\n",
       "      <td>Niedermülsen</td>\n",
       "      <td>Mülsenbach</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>563745</td>\n",
       "      <td>Johanngeorgenstadt 4</td>\n",
       "      <td>Schwarzwasser</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>583223</td>\n",
       "      <td>Reichwalde 3</td>\n",
       "      <td>Schwarzer Schöps</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>560301</td>\n",
       "      <td>Nemt 1</td>\n",
       "      <td>Mühlbach</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>583100</td>\n",
       "      <td>Löbau Stadion</td>\n",
       "      <td>Löbauer Wasser</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>550761</td>\n",
       "      <td>Liebstadt 1</td>\n",
       "      <td>Seidewitz</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>282 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pegelkennziffer             Pegelname         Gewaesser unit_q unit_w\n",
       "0            551431      Dippoldiswalde 3        Werkgraben   m³/s     cm\n",
       "1            550190          Porschdorf 1         Lachsbach   m³/s     cm\n",
       "2            663090             Tauchritz         Pließnitz   m³/s     cm\n",
       "3            564201        Niedermülsen 1        Mülsenbach   m³/s     cm\n",
       "4            564200          Niedermülsen        Mülsenbach   m³/s     cm\n",
       "..              ...                   ...               ...    ...    ...\n",
       "277          563745  Johanngeorgenstadt 4     Schwarzwasser   m³/s     cm\n",
       "278          583223          Reichwalde 3  Schwarzer Schöps   m³/s     cm\n",
       "279          560301                Nemt 1          Mühlbach   m³/s     cm\n",
       "280          583100         Löbau Stadion    Löbauer Wasser   m³/s     cm\n",
       "281          550761           Liebstadt 1         Seidewitz   m³/s     cm\n",
       "\n",
       "[282 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = pd.DataFrame(meta)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pegelkennziffer</th>\n",
       "      <th>Pegelname</th>\n",
       "      <th>Gewaesser</th>\n",
       "      <th>unit_q</th>\n",
       "      <th>unit_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>662082</td>\n",
       "      <td>Neuschönau 2</td>\n",
       "      <td>Lasur</td>\n",
       "      <td>m³/s</td>\n",
       "      <td>cm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pegelkennziffer     Pegelname Gewaesser unit_q unit_w\n",
       "115          662082  Neuschönau 2     Lasur   m³/s     cm"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata[metadata['Pegelkennziffer'] == '662082']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = 'Pegelkennziffer'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally run\n",
    "\n",
    "Now, the Q and W data can be extracted. The cool thing is, that all the id creation, data creation, merging and the mapping from our ids to the original ids and files is done by the context. This is helpful, as we less likely screw something up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nuts_id provider_id                              path\n",
      "0  DED10000      551431  ./DED/DED10000/DED10000_data.csv\n",
      "1  DED10010      550190  ./DED/DED10010/DED10010_data.csv\n",
      "2  DED10020      663090  ./DED/DED10020/DED10020_data.csv\n",
      "3  DED10030      564201  ./DED/DED10030/DED10030_data.csv\n",
      "4  DED10040      564200  ./DED/DED10040/DED10040_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/282 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 282/282 [00:15<00:00, 18.53it/s]\n"
     ]
    }
   ],
   "source": [
    "with Bundesland('Sachsen') as bl:\n",
    "    # save the metadata\n",
    "    bl.save_raw_metadata(metadata, id_column, overwrite=True)\n",
    "\n",
    "    # for reference, call the nuts-mapping as table\n",
    "    nuts_map = bl.nuts_table\n",
    "    print(nuts_map.head())\n",
    "\n",
    "    # go for each    \n",
    "    for m, q_df, w_df in tqdm(zip(meta, q, w), total=len(meta)):\n",
    "        \n",
    "        if m is not None:\n",
    "            # get the provider id\n",
    "            provider_id = str(m[id_column])\n",
    "            bl.save_timeseries(q_df, provider_id)\n",
    "            bl.save_timeseries(w_df, provider_id)\n",
    "\n",
    "    # check if there were warnings (there are warnings)\n",
    "    if len(warns) > 0:\n",
    "        log_path = bl.save_warnings(warns)\n",
    "        print(f\"There were warnings during the processing. The log can be found at: {log_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c57ebfed52ffd848a0d2f36f1ea9c0a9060c9b67397fbb725d6aa92a9494b08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
