{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baden-Württemberg\n",
    "\n",
    "Every federal state is represented by its own input directory and is processed into a NUTS level 2 directory containing a sub-folder for each discharge location. These folder names are derived from NUTS and reflect the CAMELS id. The NUTS level 2 code for Baden-Württemberg is `DE1`.\n",
    "\n",
    "To pre-process the data, you need to write (at least) two functions. One should extract all metadata and condense it into a single `pandas.DataFrame`. This is used to build the folder structure and derive the ids.\n",
    "The second function has to take an id, as provided by the state authorities, called `provider_id` and return a `pandas.DataFrame` with the transformed data. The dataframe needs the three columns `['date', 'q' | 'w', 'flag']`.\n",
    "\n",
    "For easier and unified output handling, the `camelsp` package contains a context object called `Bundesland`. It takes a number of names and abbreviations to identify the correct federal state and returns an object that holds helper and save functions.\n",
    "\n",
    "The context saves files as needed and can easily be changed to save files with different strategies, ie. fill missing data with NaN, merge data into a single file, create files for each variable or pack everything together into a netcdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from typing import Union, Dict\n",
    "import zipfile\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from camelsp import Bundesland"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The context can also be instantiated as any regular Python class, ie. to load only the default input data path, that we will user later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alexd/Projekte/CAMELS/Github/camelsp/input_data/Q_and_W/BW_Baden_Wuerttemberg'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the context also makes the input path available, if camelsp was install locally\n",
    "BASE = Bundesland('bw').input_path\n",
    "BASE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata reader\n",
    "\n",
    "Define the function that extracts / reads and eventually merges all metadata for this federal state. You can develop the function here, without using the Bundesland context and then later use the context to pass extracted metadata. The Context has a function for saving *raw* metadata, that takes a `pandas.DataFrame` and needs you to identify the id column.\n",
    "Here, *raw* refers to provider metadata, that has not yet been transformed into the CAMELS-de Metadata schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Messstellennummer</th>\n",
       "      <th>Standort</th>\n",
       "      <th>Gewässer</th>\n",
       "      <th>Ost (UTM ETRS89)</th>\n",
       "      <th>Nord (UTM ETRS89)</th>\n",
       "      <th>Pegelnullpunkt (PNP) in m</th>\n",
       "      <th>Pegelnullpunkt (PNP): Höhensystem</th>\n",
       "      <th>Einzugsgebiet in km²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>Kirchen-Hausen</td>\n",
       "      <td>Donau</td>\n",
       "      <td>476064.18</td>\n",
       "      <td>5308070.39</td>\n",
       "      <td>657,334</td>\n",
       "      <td>DHHN2016 (HS170)</td>\n",
       "      <td>758.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>Möhringen</td>\n",
       "      <td>Donau</td>\n",
       "      <td>482087.76</td>\n",
       "      <td>5310655.37</td>\n",
       "      <td>649,162</td>\n",
       "      <td>DHHN2016 (HS170)</td>\n",
       "      <td>826.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>Hundersingen</td>\n",
       "      <td>Donau</td>\n",
       "      <td>529505.85</td>\n",
       "      <td>5324430.06</td>\n",
       "      <td>542,53</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>2621.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>Berg</td>\n",
       "      <td>Donau</td>\n",
       "      <td>554281.85</td>\n",
       "      <td>5346154.31</td>\n",
       "      <td>489,903</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>4072.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129</td>\n",
       "      <td>Achstetten</td>\n",
       "      <td>Baierzer Rot</td>\n",
       "      <td>566853.80</td>\n",
       "      <td>5345973.36</td>\n",
       "      <td>489,317</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>264.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>76274</td>\n",
       "      <td>Erlenbach</td>\n",
       "      <td>Sulm</td>\n",
       "      <td>519268.06</td>\n",
       "      <td>5446405.15</td>\n",
       "      <td>160,832</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>101.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>76276</td>\n",
       "      <td>Bolheim</td>\n",
       "      <td>Brenz</td>\n",
       "      <td>585063.46</td>\n",
       "      <td>5386985.83</td>\n",
       "      <td>473,0</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>339.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>76290</td>\n",
       "      <td>Schweinhausen</td>\n",
       "      <td>Riß</td>\n",
       "      <td>558687.15</td>\n",
       "      <td>5320679.63</td>\n",
       "      <td>541,098</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>101.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>76361</td>\n",
       "      <td>Hölzlebruck</td>\n",
       "      <td>Josbach</td>\n",
       "      <td>439609.70</td>\n",
       "      <td>5308305.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>76436</td>\n",
       "      <td>Oppenweiler</td>\n",
       "      <td>Murr</td>\n",
       "      <td>534148.01</td>\n",
       "      <td>5426466.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Messstellennummer        Standort      Gewässer  Ost (UTM ETRS89)  \\\n",
       "0                  105  Kirchen-Hausen         Donau         476064.18   \n",
       "1                  106       Möhringen         Donau         482087.76   \n",
       "2                  120    Hundersingen         Donau         529505.85   \n",
       "3                  125            Berg         Donau         554281.85   \n",
       "4                  129      Achstetten  Baierzer Rot         566853.80   \n",
       "..                 ...             ...           ...               ...   \n",
       "254              76274       Erlenbach          Sulm         519268.06   \n",
       "255              76276         Bolheim         Brenz         585063.46   \n",
       "256              76290   Schweinhausen           Riß         558687.15   \n",
       "257              76361     Hölzlebruck       Josbach         439609.70   \n",
       "258              76436     Oppenweiler          Murr         534148.01   \n",
       "\n",
       "     Nord (UTM ETRS89) Pegelnullpunkt (PNP) in m  \\\n",
       "0           5308070.39                   657,334   \n",
       "1           5310655.37                   649,162   \n",
       "2           5324430.06                    542,53   \n",
       "3           5346154.31                   489,903   \n",
       "4           5345973.36                   489,317   \n",
       "..                 ...                       ...   \n",
       "254         5446405.15                   160,832   \n",
       "255         5386985.83                     473,0   \n",
       "256         5320679.63                   541,098   \n",
       "257         5308305.12                       NaN   \n",
       "258         5426466.13                       NaN   \n",
       "\n",
       "    Pegelnullpunkt (PNP): Höhensystem  Einzugsgebiet in km²  \n",
       "0                    DHHN2016 (HS170)               758.528  \n",
       "1                    DHHN2016 (HS170)               826.963  \n",
       "2                      DHHN12 (HS130)              2621.324  \n",
       "3                      DHHN12 (HS130)              4072.790  \n",
       "4                      DHHN12 (HS130)               264.393  \n",
       "..                                ...                   ...  \n",
       "254                    DHHN12 (HS130)               101.510  \n",
       "255                    DHHN12 (HS130)               339.811  \n",
       "256                    DHHN12 (HS130)               101.589  \n",
       "257                               NaN                47.310  \n",
       "258                               NaN               180.694  \n",
       "\n",
       "[259 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the function \n",
    "def read_meta(base_path) -> pd.DataFrame:\n",
    "    path = os.path.join(base_path, 'BW_Meta.xlsx')\n",
    "    meta = pd.read_excel(path)\n",
    "    return meta\n",
    "\n",
    "# test it here\n",
    "metadata = read_meta(BASE)\n",
    "\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stations without data\n",
    "There are some stations in the metadata for which we do not have datafiles.  \n",
    "We delete them for now from the metadata!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Messstellennummer</th>\n",
       "      <th>Standort</th>\n",
       "      <th>Gewässer</th>\n",
       "      <th>Ost (UTM ETRS89)</th>\n",
       "      <th>Nord (UTM ETRS89)</th>\n",
       "      <th>Pegelnullpunkt (PNP) in m</th>\n",
       "      <th>Pegelnullpunkt (PNP): Höhensystem</th>\n",
       "      <th>Einzugsgebiet in km²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>Kirchen-Hausen</td>\n",
       "      <td>Donau</td>\n",
       "      <td>476064.18</td>\n",
       "      <td>5308070.39</td>\n",
       "      <td>657,334</td>\n",
       "      <td>DHHN2016 (HS170)</td>\n",
       "      <td>758.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>Möhringen</td>\n",
       "      <td>Donau</td>\n",
       "      <td>482087.76</td>\n",
       "      <td>5310655.37</td>\n",
       "      <td>649,162</td>\n",
       "      <td>DHHN2016 (HS170)</td>\n",
       "      <td>826.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>Hundersingen</td>\n",
       "      <td>Donau</td>\n",
       "      <td>529505.85</td>\n",
       "      <td>5324430.06</td>\n",
       "      <td>542,53</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>2621.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>Berg</td>\n",
       "      <td>Donau</td>\n",
       "      <td>554281.85</td>\n",
       "      <td>5346154.31</td>\n",
       "      <td>489,903</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>4072.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129</td>\n",
       "      <td>Achstetten</td>\n",
       "      <td>Baierzer Rot</td>\n",
       "      <td>566853.80</td>\n",
       "      <td>5345973.36</td>\n",
       "      <td>489,317</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>264.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>76273</td>\n",
       "      <td>Blaubeuren</td>\n",
       "      <td>Blautopf</td>\n",
       "      <td>557987.28</td>\n",
       "      <td>5362854.60</td>\n",
       "      <td>511,871</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>76274</td>\n",
       "      <td>Erlenbach</td>\n",
       "      <td>Sulm</td>\n",
       "      <td>519268.06</td>\n",
       "      <td>5446405.15</td>\n",
       "      <td>160,832</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>101.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>76276</td>\n",
       "      <td>Bolheim</td>\n",
       "      <td>Brenz</td>\n",
       "      <td>585063.46</td>\n",
       "      <td>5386985.83</td>\n",
       "      <td>473,0</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>339.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>76290</td>\n",
       "      <td>Schweinhausen</td>\n",
       "      <td>Riß</td>\n",
       "      <td>558687.15</td>\n",
       "      <td>5320679.63</td>\n",
       "      <td>541,098</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>101.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>76436</td>\n",
       "      <td>Oppenweiler</td>\n",
       "      <td>Murr</td>\n",
       "      <td>534148.01</td>\n",
       "      <td>5426466.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Messstellennummer        Standort      Gewässer  Ost (UTM ETRS89)  \\\n",
       "0                  105  Kirchen-Hausen         Donau         476064.18   \n",
       "1                  106       Möhringen         Donau         482087.76   \n",
       "2                  120    Hundersingen         Donau         529505.85   \n",
       "3                  125            Berg         Donau         554281.85   \n",
       "4                  129      Achstetten  Baierzer Rot         566853.80   \n",
       "..                 ...             ...           ...               ...   \n",
       "247              76273      Blaubeuren      Blautopf         557987.28   \n",
       "248              76274       Erlenbach          Sulm         519268.06   \n",
       "249              76276         Bolheim         Brenz         585063.46   \n",
       "250              76290   Schweinhausen           Riß         558687.15   \n",
       "251              76436     Oppenweiler          Murr         534148.01   \n",
       "\n",
       "     Nord (UTM ETRS89) Pegelnullpunkt (PNP) in m  \\\n",
       "0           5308070.39                   657,334   \n",
       "1           5310655.37                   649,162   \n",
       "2           5324430.06                    542,53   \n",
       "3           5346154.31                   489,903   \n",
       "4           5345973.36                   489,317   \n",
       "..                 ...                       ...   \n",
       "247         5362854.60                   511,871   \n",
       "248         5446405.15                   160,832   \n",
       "249         5386985.83                     473,0   \n",
       "250         5320679.63                   541,098   \n",
       "251         5426466.13                       NaN   \n",
       "\n",
       "    Pegelnullpunkt (PNP): Höhensystem  Einzugsgebiet in km²  \n",
       "0                    DHHN2016 (HS170)               758.528  \n",
       "1                    DHHN2016 (HS170)               826.963  \n",
       "2                      DHHN12 (HS130)              2621.324  \n",
       "3                      DHHN12 (HS130)              4072.790  \n",
       "4                      DHHN12 (HS130)               264.393  \n",
       "..                                ...                   ...  \n",
       "247                    DHHN12 (HS130)                 0.067  \n",
       "248                    DHHN12 (HS130)               101.510  \n",
       "249                    DHHN12 (HS130)               339.811  \n",
       "250                    DHHN12 (HS130)               101.589  \n",
       "251                               NaN               180.694  \n",
       "\n",
       "[252 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_without_data = [1159, 3310, 3339, 32366, 60681, 76167, 76361]\n",
    "\n",
    "# drop the ids without data from metadata\n",
    "metadata = metadata[~metadata['Messstellennummer'].isin(ids_without_data)].reset_index(drop=True)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the id column will be Messstellennummer\n",
    "id_column = 'Messstellennummer'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## file extract and parse\n",
    "\n",
    "I'll keep the files in the zip, just because. In baWü these zips are nicely flat-packed and there is actually no need to extract the zip. Later, we might want to extract and change the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>q</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1922-11-01</td>\n",
       "      <td>12.2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1922-11-02</td>\n",
       "      <td>21.9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1922-11-03</td>\n",
       "      <td>58.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1922-11-04</td>\n",
       "      <td>57.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1922-11-05</td>\n",
       "      <td>46.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36216</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>17.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36217</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>23.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36218</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>36.6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36219</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>39.4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36220</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>34.7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36221 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     q   flag\n",
       "0     1922-11-01  12.2  False\n",
       "1     1922-11-02  21.9  False\n",
       "2     1922-11-03  58.1  False\n",
       "3     1922-11-04  57.5  False\n",
       "4     1922-11-05  46.1  False\n",
       "...          ...   ...    ...\n",
       "36216 2021-12-27  17.0   True\n",
       "36217 2021-12-28  23.2   True\n",
       "36218 2021-12-29  36.6   True\n",
       "36219 2021-12-30  39.4   True\n",
       "36220 2021-12-31  34.7   True\n",
       "\n",
       "[36221 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# helper to map ids to filenames\n",
    "def get_filename_mapping(zippath: str) -> Dict[str, str]:\n",
    "    with zipfile.ZipFile(zippath) as z:\n",
    "        return {f\"{f.filename.split('-')[0]}\": f.filename for f in z.filelist}\n",
    "\n",
    "def extract_file(nr: Union[int, str], variable: str, zippath: str, not_exists = 'raise') -> pd.DataFrame:\n",
    "    # get filename mapping\n",
    "    fmap = get_filename_mapping(zippath)\n",
    "    \n",
    "    # always use string\n",
    "    fname = str(nr)\n",
    "\n",
    "    # search the file \n",
    "    if fname in fmap.values():\n",
    "        fname = fname\n",
    "    elif fname in fmap.keys():\n",
    "        fname = fmap[fname]\n",
    "    else:\n",
    "        FileNotFoundError(f\"nr {nr} is nothing we would expect. Use a LUBW Messstellennummer or filename in the zip\")\n",
    "    \n",
    "    # go for the file\n",
    "    with zipfile.ZipFile(zippath) as z:\n",
    "        if fname not in [f.filename for f in z.filelist]:\n",
    "            # TODO: here, might want to warn and return an df filled with NAN\n",
    "            if not_exists == 'raise':\n",
    "                raise FileNotFoundError(f\"{fname} is not in {zippath}\")\n",
    "            else:\n",
    "                return pd.DataFrame(columns=['date', variable.lower(), 'flag'])\n",
    "        \n",
    "        # raw content\n",
    "        raw = pd.read_csv(z.open(fname), encoding='latin1', skiprows=3, sep=';', decimal=',', na_values=-999)\n",
    "        \n",
    "        # 'q' data\n",
    "        if 'Q' in raw.columns:\n",
    "            return pd.DataFrame({\n",
    "                'date': [dt.strptime(_, '%d.%m.%Y') for _ in raw.Datum],\n",
    "                'q': raw.Q.values,\n",
    "                'flag': [_.lower().strip() == 'ja' for _ in raw['Geprüft (nein=ungeprüfte Rohdaten)']],\n",
    "\n",
    "            })\n",
    "        # w data\n",
    "        else:\n",
    "            return pd.DataFrame({\n",
    "                'date': [dt.strptime(_, '%d.%m.%Y') for _ in raw.Datum],\n",
    "                'w': raw.W.values,\n",
    "                'flag': [_.lower().strip() == 'ja' for _ in raw['Geprüft (nein=ungeprüfte Rohdaten)']],\n",
    "\n",
    "            })\n",
    "\n",
    "# test \n",
    "df = extract_file(105, 'q', os.path.join(BASE, 'BW_Q.zip'))\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally run\n",
    "\n",
    "Now, the Q and W data can be extracted along with the metadata. The cool thing is, that all the id creation, data creation, merging and the mapping from our ids to the original ids and files is done by the context. This is helpful, as we less likely screw something up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't find the nuts_mapping at /home/camel/camelsp/output_data/metadata/nuts_mapping.json, returning empty mapping.\n",
      "    nuts_id provider_id                              path\n",
      "0  DE110000         105  ./DE1/DE110000/DE110000_data.csv\n",
      "1  DE110010         106  ./DE1/DE110010/DE110010_data.csv\n",
      "2  DE110020         120  ./DE1/DE110020/DE110020_data.csv\n",
      "3  DE110030         125  ./DE1/DE110030/DE110030_data.csv\n",
      "4  DE110040         129  ./DE1/DE110040/DE110040_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 252/252 [02:03<00:00,  2.04it/s]\n"
     ]
    }
   ],
   "source": [
    "with Bundesland('Ba-Wü') as bl:\n",
    "    # save the metadata\n",
    "    bl.save_raw_metadata(metadata, id_column, overwrite=True)\n",
    "\n",
    "    # for reference, call the nuts-mapping as table\n",
    "    nuts_map = bl.nuts_table\n",
    "    print(nuts_map.head())\n",
    "\n",
    "    # join the path for two zips\n",
    "    q_zip_path = os.path.join(bl.input_path, 'BW_Q.zip')\n",
    "    w_zip_path = os.path.join(bl.input_path, 'BW_W.zip')\n",
    "    \n",
    "    # go for all ids\n",
    "    for provider_id in tqdm(nuts_map.provider_id):\n",
    "        # extract the file for this provider\n",
    "        q_df = extract_file(provider_id, 'q', q_zip_path, not_exists='fill_nan')\n",
    "        w_df = extract_file(provider_id, 'w', w_zip_path, not_exists='fill_nan')\n",
    "\n",
    "        # save\n",
    "        bl.save_timeseries(q_df, provider_id)\n",
    "        bl.save_timeseries(w_df, provider_id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
