{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baden-Württemberg\n",
    "\n",
    "Every federal state is represented by its own input directory and is processed into a NUTS level 2 directory containing a sub-folder for each discharge location. These folder names are derived from NUTS and reflect the CAMELS id. The NUTS level 2 code for Baden-Württemberg is `DE1`.\n",
    "\n",
    "To pre-process the data, you need to write (at least) two functions. One should extract all metadata and condense it into a single `pandas.DataFrame`. This is used to build the folder structure and derive the ids.\n",
    "The second function has to take an id, as provided by the state authorities, called `provider_id` and return a `pandas.DataFrame` with the transformed data. The dataframe needs the three columns `['date', 'q' | 'w', 'flag']`.\n",
    "\n",
    "For easier and unified output handling, the `camelsp` package contains a context object called `Bundesland`. It takes a number of names and abbreviations to identify the correct federal state and returns an object that holds helper and save functions.\n",
    "\n",
    "The context saves files as needed and can easily be changed to save files with different strategies, ie. fill missing data with NaN, merge data into a single file, create files for each variable or pack everything together into a netcdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from typing import Union, Dict\n",
    "import zipfile\n",
    "from datetime import datetime as dt\n",
    "\n",
    "from camelsp import Bundesland "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The context can also be instantiated as any regular Python class, ie. to load only the default input data path, that we will user later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/alexd/Projekte/CAMELS/Github/camelsp/input_data/BW_Baden_Wuerttemberg'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the context also makes the input path available, if camelsp was install locally\n",
    "BASE = Bundesland('bw').input_path\n",
    "BASE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata reader\n",
    "\n",
    "Define the function that extracts / reads and eventually merges all metadata for this federal state. You can develop the function here, without using the Bundesland context and then later use the context to pass extracted metadata. The Context has a function for saving *raw* metadata, that takes a `pandas.DataFrame` and needs you to identify the id column.\n",
    "Here, *raw* refers to provider metadata, that has not yet been transformed into the CAMELS-de Metadata schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Messstellennummer</th>\n",
       "      <th>Standort</th>\n",
       "      <th>Gewässer</th>\n",
       "      <th>Ost (UTM ETRS89)</th>\n",
       "      <th>Nord (UTM ETRS89)</th>\n",
       "      <th>Pegelnullpunkt (PNP) in m</th>\n",
       "      <th>Pegelnullpunkt (PNP): Höhensystem</th>\n",
       "      <th>Einzugsgebiet in km²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>Kirchen-Hausen</td>\n",
       "      <td>Donau</td>\n",
       "      <td>476064.18</td>\n",
       "      <td>5308070.39</td>\n",
       "      <td>657,334</td>\n",
       "      <td>DHHN2016 (HS170)</td>\n",
       "      <td>758.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>Möhringen</td>\n",
       "      <td>Donau</td>\n",
       "      <td>482087.76</td>\n",
       "      <td>5310655.37</td>\n",
       "      <td>649,162</td>\n",
       "      <td>DHHN2016 (HS170)</td>\n",
       "      <td>826.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>Hundersingen</td>\n",
       "      <td>Donau</td>\n",
       "      <td>529505.85</td>\n",
       "      <td>5324430.06</td>\n",
       "      <td>542,53</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>2621.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>Berg</td>\n",
       "      <td>Donau</td>\n",
       "      <td>554281.85</td>\n",
       "      <td>5346154.31</td>\n",
       "      <td>489,903</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>4072.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129</td>\n",
       "      <td>Achstetten</td>\n",
       "      <td>Baierzer Rot</td>\n",
       "      <td>566853.80</td>\n",
       "      <td>5345973.36</td>\n",
       "      <td>489,317</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>264.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>76274</td>\n",
       "      <td>Erlenbach</td>\n",
       "      <td>Sulm</td>\n",
       "      <td>519268.06</td>\n",
       "      <td>5446405.15</td>\n",
       "      <td>160,832</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>101.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>76276</td>\n",
       "      <td>Bolheim</td>\n",
       "      <td>Brenz</td>\n",
       "      <td>585063.46</td>\n",
       "      <td>5386985.83</td>\n",
       "      <td>473,0</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>339.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>76290</td>\n",
       "      <td>Schweinhausen</td>\n",
       "      <td>Riß</td>\n",
       "      <td>558687.15</td>\n",
       "      <td>5320679.63</td>\n",
       "      <td>541,098</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>101.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>76361</td>\n",
       "      <td>Hölzlebruck</td>\n",
       "      <td>Josbach</td>\n",
       "      <td>439609.70</td>\n",
       "      <td>5308305.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>76436</td>\n",
       "      <td>Oppenweiler</td>\n",
       "      <td>Murr</td>\n",
       "      <td>534148.01</td>\n",
       "      <td>5426466.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Messstellennummer        Standort      Gewässer  Ost (UTM ETRS89)  \\\n",
       "0                  105  Kirchen-Hausen         Donau         476064.18   \n",
       "1                  106       Möhringen         Donau         482087.76   \n",
       "2                  120    Hundersingen         Donau         529505.85   \n",
       "3                  125            Berg         Donau         554281.85   \n",
       "4                  129      Achstetten  Baierzer Rot         566853.80   \n",
       "..                 ...             ...           ...               ...   \n",
       "254              76274       Erlenbach          Sulm         519268.06   \n",
       "255              76276         Bolheim         Brenz         585063.46   \n",
       "256              76290   Schweinhausen           Riß         558687.15   \n",
       "257              76361     Hölzlebruck       Josbach         439609.70   \n",
       "258              76436     Oppenweiler          Murr         534148.01   \n",
       "\n",
       "     Nord (UTM ETRS89) Pegelnullpunkt (PNP) in m  \\\n",
       "0           5308070.39                   657,334   \n",
       "1           5310655.37                   649,162   \n",
       "2           5324430.06                    542,53   \n",
       "3           5346154.31                   489,903   \n",
       "4           5345973.36                   489,317   \n",
       "..                 ...                       ...   \n",
       "254         5446405.15                   160,832   \n",
       "255         5386985.83                     473,0   \n",
       "256         5320679.63                   541,098   \n",
       "257         5308305.12                       NaN   \n",
       "258         5426466.13                       NaN   \n",
       "\n",
       "    Pegelnullpunkt (PNP): Höhensystem  Einzugsgebiet in km²  \n",
       "0                    DHHN2016 (HS170)               758.528  \n",
       "1                    DHHN2016 (HS170)               826.963  \n",
       "2                      DHHN12 (HS130)              2621.324  \n",
       "3                      DHHN12 (HS130)              4072.790  \n",
       "4                      DHHN12 (HS130)               264.393  \n",
       "..                                ...                   ...  \n",
       "254                    DHHN12 (HS130)               101.510  \n",
       "255                    DHHN12 (HS130)               339.811  \n",
       "256                    DHHN12 (HS130)               101.589  \n",
       "257                               NaN                47.310  \n",
       "258                               NaN               180.694  \n",
       "\n",
       "[259 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the function \n",
    "def read_meta(base_path) -> pd.DataFrame:\n",
    "    path = os.path.join(base_path, 'BW_Meta.xlsx')\n",
    "    meta = pd.read_excel(path)\n",
    "    return meta\n",
    "\n",
    "# test it here\n",
    "metadata = read_meta(BASE)\n",
    "\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stations without data\n",
    "There are some stations in the metadata for which we do not have datafiles.  \n",
    "We delete them for now from the metadata!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Messstellennummer</th>\n",
       "      <th>Standort</th>\n",
       "      <th>Gewässer</th>\n",
       "      <th>Ost (UTM ETRS89)</th>\n",
       "      <th>Nord (UTM ETRS89)</th>\n",
       "      <th>Pegelnullpunkt (PNP) in m</th>\n",
       "      <th>Pegelnullpunkt (PNP): Höhensystem</th>\n",
       "      <th>Einzugsgebiet in km²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>Kirchen-Hausen</td>\n",
       "      <td>Donau</td>\n",
       "      <td>476064.18</td>\n",
       "      <td>5308070.39</td>\n",
       "      <td>657,334</td>\n",
       "      <td>DHHN2016 (HS170)</td>\n",
       "      <td>758.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>Möhringen</td>\n",
       "      <td>Donau</td>\n",
       "      <td>482087.76</td>\n",
       "      <td>5310655.37</td>\n",
       "      <td>649,162</td>\n",
       "      <td>DHHN2016 (HS170)</td>\n",
       "      <td>826.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120</td>\n",
       "      <td>Hundersingen</td>\n",
       "      <td>Donau</td>\n",
       "      <td>529505.85</td>\n",
       "      <td>5324430.06</td>\n",
       "      <td>542,53</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>2621.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>Berg</td>\n",
       "      <td>Donau</td>\n",
       "      <td>554281.85</td>\n",
       "      <td>5346154.31</td>\n",
       "      <td>489,903</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>4072.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129</td>\n",
       "      <td>Achstetten</td>\n",
       "      <td>Baierzer Rot</td>\n",
       "      <td>566853.80</td>\n",
       "      <td>5345973.36</td>\n",
       "      <td>489,317</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>264.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>76273</td>\n",
       "      <td>Blaubeuren</td>\n",
       "      <td>Blautopf</td>\n",
       "      <td>557987.28</td>\n",
       "      <td>5362854.60</td>\n",
       "      <td>511,871</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>76274</td>\n",
       "      <td>Erlenbach</td>\n",
       "      <td>Sulm</td>\n",
       "      <td>519268.06</td>\n",
       "      <td>5446405.15</td>\n",
       "      <td>160,832</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>101.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>76276</td>\n",
       "      <td>Bolheim</td>\n",
       "      <td>Brenz</td>\n",
       "      <td>585063.46</td>\n",
       "      <td>5386985.83</td>\n",
       "      <td>473,0</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>339.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>76290</td>\n",
       "      <td>Schweinhausen</td>\n",
       "      <td>Riß</td>\n",
       "      <td>558687.15</td>\n",
       "      <td>5320679.63</td>\n",
       "      <td>541,098</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>101.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>76436</td>\n",
       "      <td>Oppenweiler</td>\n",
       "      <td>Murr</td>\n",
       "      <td>534148.01</td>\n",
       "      <td>5426466.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Messstellennummer        Standort      Gewässer  Ost (UTM ETRS89)  \\\n",
       "0                  105  Kirchen-Hausen         Donau         476064.18   \n",
       "1                  106       Möhringen         Donau         482087.76   \n",
       "2                  120    Hundersingen         Donau         529505.85   \n",
       "3                  125            Berg         Donau         554281.85   \n",
       "4                  129      Achstetten  Baierzer Rot         566853.80   \n",
       "..                 ...             ...           ...               ...   \n",
       "247              76273      Blaubeuren      Blautopf         557987.28   \n",
       "248              76274       Erlenbach          Sulm         519268.06   \n",
       "249              76276         Bolheim         Brenz         585063.46   \n",
       "250              76290   Schweinhausen           Riß         558687.15   \n",
       "251              76436     Oppenweiler          Murr         534148.01   \n",
       "\n",
       "     Nord (UTM ETRS89) Pegelnullpunkt (PNP) in m  \\\n",
       "0           5308070.39                   657,334   \n",
       "1           5310655.37                   649,162   \n",
       "2           5324430.06                    542,53   \n",
       "3           5346154.31                   489,903   \n",
       "4           5345973.36                   489,317   \n",
       "..                 ...                       ...   \n",
       "247         5362854.60                   511,871   \n",
       "248         5446405.15                   160,832   \n",
       "249         5386985.83                     473,0   \n",
       "250         5320679.63                   541,098   \n",
       "251         5426466.13                       NaN   \n",
       "\n",
       "    Pegelnullpunkt (PNP): Höhensystem  Einzugsgebiet in km²  \n",
       "0                    DHHN2016 (HS170)               758.528  \n",
       "1                    DHHN2016 (HS170)               826.963  \n",
       "2                      DHHN12 (HS130)              2621.324  \n",
       "3                      DHHN12 (HS130)              4072.790  \n",
       "4                      DHHN12 (HS130)               264.393  \n",
       "..                                ...                   ...  \n",
       "247                    DHHN12 (HS130)                 0.067  \n",
       "248                    DHHN12 (HS130)               101.510  \n",
       "249                    DHHN12 (HS130)               339.811  \n",
       "250                    DHHN12 (HS130)               101.589  \n",
       "251                               NaN               180.694  \n",
       "\n",
       "[252 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_without_data = [1159, 3310, 3339, 32366, 60681, 76167, 76361]\n",
    "\n",
    "# drop the ids without data from metadata\n",
    "metadata = metadata[~metadata['Messstellennummer'].isin(ids_without_data)].reset_index(drop=True)\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the id column will be Messstellennummer\n",
    "id_column = 'Messstellennummer'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## file extract and parse\n",
    "\n",
    "I'll keep the files in the zip, just because. In baWü these zips are nicely flat-packed and there is actually no need to extract the zip. Later, we might want to extract and change the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>q</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1922-11-01</td>\n",
       "      <td>12.2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1922-11-02</td>\n",
       "      <td>21.9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1922-11-03</td>\n",
       "      <td>58.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1922-11-04</td>\n",
       "      <td>57.5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1922-11-05</td>\n",
       "      <td>46.1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36216</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>17.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36217</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>23.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36218</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>36.6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36219</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>39.4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36220</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>34.7</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36221 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date     q   flag\n",
       "0     1922-11-01  12.2  False\n",
       "1     1922-11-02  21.9  False\n",
       "2     1922-11-03  58.1  False\n",
       "3     1922-11-04  57.5  False\n",
       "4     1922-11-05  46.1  False\n",
       "...          ...   ...    ...\n",
       "36216 2021-12-27  17.0   True\n",
       "36217 2021-12-28  23.2   True\n",
       "36218 2021-12-29  36.6   True\n",
       "36219 2021-12-30  39.4   True\n",
       "36220 2021-12-31  34.7   True\n",
       "\n",
       "[36221 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# helper to map ids to filenames\n",
    "def get_filename_mapping(zippath: str) -> Dict[str, str]:\n",
    "    with zipfile.ZipFile(zippath) as z:\n",
    "        return {f\"{f.filename.split('-')[0]}\": f.filename for f in z.filelist}\n",
    "\n",
    "def extract_file(nr: Union[int, str], variable: str, zippath: str, not_exists = 'raise') -> pd.DataFrame:\n",
    "    # get filename mapping\n",
    "    fmap = get_filename_mapping(zippath)\n",
    "    \n",
    "    # always use string\n",
    "    fname = str(nr)\n",
    "\n",
    "    # search the file \n",
    "    if fname in fmap.values():\n",
    "        fname = fname\n",
    "    elif fname in fmap.keys():\n",
    "        fname = fmap[fname]\n",
    "    else:\n",
    "        FileNotFoundError(f\"nr {nr} is nothing we would expect. Use a LUBW Messstellennummer or filename in the zip\")\n",
    "    \n",
    "    # go for the file\n",
    "    with zipfile.ZipFile(zippath) as z:\n",
    "        if fname not in [f.filename for f in z.filelist]:\n",
    "            # TODO: here, might want to warn and return an df filled with NAN\n",
    "            if not_exists == 'raise':\n",
    "                raise FileNotFoundError(f\"{fname} is not in {zippath}\")\n",
    "            else:\n",
    "                return pd.DataFrame(columns=['date', variable.lower(), 'flag'])\n",
    "        \n",
    "        # raw content\n",
    "        raw = pd.read_csv(z.open(fname), encoding='latin1', skiprows=3, sep=';', decimal=',', na_values=-999)\n",
    "        \n",
    "        # 'q' data\n",
    "        if 'Q' in raw.columns:\n",
    "            return pd.DataFrame({\n",
    "                'date': [dt.strptime(_, '%d.%m.%Y') for _ in raw.Datum],\n",
    "                'q': raw.Q.values,\n",
    "                'flag': [_.lower().strip() == 'ja' for _ in raw['Geprüft (nein=ungeprüfte Rohdaten)']],\n",
    "\n",
    "            })\n",
    "        # w data\n",
    "        else:\n",
    "            return pd.DataFrame({\n",
    "                'date': [dt.strptime(_, '%d.%m.%Y') for _ in raw.Datum],\n",
    "                'w': raw.W.values,\n",
    "                'flag': [_.lower().strip() == 'ja' for _ in raw['Geprüft (nein=ungeprüfte Rohdaten)']],\n",
    "\n",
    "            })\n",
    "\n",
    "# test \n",
    "df = extract_file(105, 'q', '../input_data/BW_Baden_Wuerttemberg/BW_Q.zip')\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally run\n",
    "\n",
    "Now, the Q and W data can be extracted along with the metadata. The cool thing is, that all the id creation, data creation, merging and the mapping from our ids to the original ids and files is done by the context. This is helpful, as we less likely screw something up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't find the nuts_mapping at /home/alexd/Projekte/CAMELS/Github/camelsp/output_data/metadata/nuts_mapping.json, returning empty mapping.\n",
      "    nuts_id provider_id                              path\n",
      "0  DE110000         105  ./DE1/DE110000/DE110000_data.csv\n",
      "1  DE110010         106  ./DE1/DE110010/DE110010_data.csv\n",
      "2  DE110020         120  ./DE1/DE110020/DE110020_data.csv\n",
      "3  DE110030         125  ./DE1/DE110030/DE110030_data.csv\n",
      "4  DE110040         129  ./DE1/DE110040/DE110040_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/252 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 252/252 [00:47<00:00,  5.27it/s]\n"
     ]
    }
   ],
   "source": [
    "with Bundesland('Ba-Wü') as bl:\n",
    "    # save the metadata\n",
    "    bl.save_raw_metadata(metadata, id_column, overwrite=True)\n",
    "\n",
    "    # for reference, call the nuts-mapping as table\n",
    "    nuts_map = bl.nuts_table\n",
    "    print(nuts_map.head())\n",
    "\n",
    "    # join the path for two zips\n",
    "    q_zip_path = os.path.join(bl.input_path, 'BW_Q.zip')\n",
    "    w_zip_path = os.path.join(bl.input_path, 'BW_W.zip')\n",
    "    \n",
    "    # go for all ids\n",
    "    for provider_id in tqdm(nuts_map.provider_id):\n",
    "        # extract the file for this provider\n",
    "        q_df = extract_file(provider_id, 'q', q_zip_path, not_exists='fill_nan')\n",
    "        w_df = extract_file(provider_id, 'w', w_zip_path, not_exists='fill_nan')\n",
    "\n",
    "        # save\n",
    "        bl.save_timeseries(q_df, provider_id)\n",
    "        bl.save_timeseries(w_df, provider_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empty CSV files\n",
    "\n",
    "There are some empty .csv files in the output, which only contain the header but not data.  \n",
    "In the following part, we will investigate why (it's the `nuts_mapping`!)  \n",
    "\n",
    "Already deleted from metadata above!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CSV file '../output_data/DE1/DE110780/DE110780_data.csv' is empty or only has a header.\n",
      "The CSV file '../output_data/DE1/DE112570/DE112570_data.csv' is empty or only has a header.\n",
      "The CSV file '../output_data/DE1/DE112290/DE112290_data.csv' is empty or only has a header.\n",
      "The CSV file '../output_data/DE1/DE111450/DE111450_data.csv' is empty or only has a header.\n",
      "The CSV file '../output_data/DE1/DE111570/DE111570_data.csv' is empty or only has a header.\n",
      "The CSV file '../output_data/DE1/DE111850/DE111850_data.csv' is empty or only has a header.\n",
      "The CSV file '../output_data/DE1/DE112110/DE112110_data.csv' is empty or only has a header.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the path to the parent folder containing the subfolders you want to check\n",
    "parent_folder = \"../output_data/DE1/\"\n",
    "\n",
    "# Function to check if a CSV file has data (ignores the first line)\n",
    "def has_data_csv(file_path):\n",
    "    with open(file_path, 'r') as csv_file:\n",
    "        # Skip the header line\n",
    "        next(csv_file, None)\n",
    "        # Check if there's any content remaining\n",
    "        return any(line.strip() for line in csv_file)\n",
    "\n",
    "empty_csv_files = []\n",
    "\n",
    "# Loop through subdirectories and find CSV files\n",
    "for root, dirs, files in os.walk(parent_folder):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            csv_path = os.path.join(root, file)\n",
    "            if not has_data_csv(csv_path):\n",
    "                empty_csv_files.append(csv_path)\n",
    "                print(f\"The CSV file '{csv_path}' is empty or only has a header.\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These provider ids have not data: ['1159', '3310', '3339', '32366', '60681', '76167', '76361']\n"
     ]
    }
   ],
   "source": [
    "# find the provider id for the nuts_ids, to see if input data was provided in the zip files!\n",
    "nuts_table = Bundesland('DE1').nuts_table\n",
    "\n",
    "empty_nuts = [empty_csv_file.split('0/')[1].split('_')[0] for empty_csv_file in empty_csv_files]\n",
    "\n",
    "empty_provider_ids = list(nuts_table[nuts_table['nuts_id'].isin(empty_nuts)]['provider_id'])\n",
    "\n",
    "print(f\"These provider ids have not data: {empty_provider_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Messstellennummer</th>\n",
       "      <th>Standort</th>\n",
       "      <th>Gewässer</th>\n",
       "      <th>Ost (UTM ETRS89)</th>\n",
       "      <th>Nord (UTM ETRS89)</th>\n",
       "      <th>Pegelnullpunkt (PNP) in m</th>\n",
       "      <th>Pegelnullpunkt (PNP): Höhensystem</th>\n",
       "      <th>Einzugsgebiet in km²</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1159</td>\n",
       "      <td>Mengen (Add.)</td>\n",
       "      <td>Ablach</td>\n",
       "      <td>522471.63</td>\n",
       "      <td>5320581.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>423.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>3310</td>\n",
       "      <td>Wahlwies (Add.)</td>\n",
       "      <td>Stockacher Aach</td>\n",
       "      <td>497467.63</td>\n",
       "      <td>5295751.40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>215.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>3339</td>\n",
       "      <td>Riegel (Add.)</td>\n",
       "      <td>Elz</td>\n",
       "      <td>407326.46</td>\n",
       "      <td>5334103.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1113.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>32366</td>\n",
       "      <td>Märkt</td>\n",
       "      <td>Kander</td>\n",
       "      <td>392894.28</td>\n",
       "      <td>5276558.79</td>\n",
       "      <td>241</td>\n",
       "      <td>DHHN12 (HS130)</td>\n",
       "      <td>81.451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>60681</td>\n",
       "      <td>Grünsfeld (Add.)</td>\n",
       "      <td>Grünbach</td>\n",
       "      <td>553692.52</td>\n",
       "      <td>5495000.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>227.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>76167</td>\n",
       "      <td>Bleibach-WKA (Add.)</td>\n",
       "      <td>Elz</td>\n",
       "      <td>425383.29</td>\n",
       "      <td>5331279.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>76361</td>\n",
       "      <td>Hölzlebruck</td>\n",
       "      <td>Josbach</td>\n",
       "      <td>439609.70</td>\n",
       "      <td>5308305.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Messstellennummer             Standort         Gewässer  \\\n",
       "78                1159        Mengen (Add.)           Ablach   \n",
       "145               3310      Wahlwies (Add.)  Stockacher Aach   \n",
       "157               3339        Riegel (Add.)              Elz   \n",
       "185              32366                Märkt           Kander   \n",
       "211              60681     Grünsfeld (Add.)         Grünbach   \n",
       "229              76167  Bleibach-WKA (Add.)              Elz   \n",
       "257              76361          Hölzlebruck          Josbach   \n",
       "\n",
       "     Ost (UTM ETRS89)  Nord (UTM ETRS89) Pegelnullpunkt (PNP) in m  \\\n",
       "78          522471.63         5320581.58                       NaN   \n",
       "145         497467.63         5295751.40                       NaN   \n",
       "157         407326.46         5334103.93                       NaN   \n",
       "185         392894.28         5276558.79                       241   \n",
       "211         553692.52         5495000.63                       NaN   \n",
       "229         425383.29         5331279.98                       NaN   \n",
       "257         439609.70         5308305.12                       NaN   \n",
       "\n",
       "    Pegelnullpunkt (PNP): Höhensystem  Einzugsgebiet in km²  \n",
       "78                                NaN               423.000  \n",
       "145                               NaN               215.355  \n",
       "157                               NaN              1113.680  \n",
       "185                    DHHN12 (HS130)                81.451  \n",
       "211                               NaN               227.790  \n",
       "229                               NaN               154.000  \n",
       "257                               NaN                47.310  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bl = Bundesland('DE1')\n",
    "\n",
    "metadata[metadata['Messstellennummer'].isin([int(i) for i in empty_provider_ids])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for provider_id 1159\n",
      "No data for provider_id 3310\n",
      "No data for provider_id 3339\n",
      "No data for provider_id 32366\n",
      "No data for provider_id 60681\n",
      "No data for provider_id 76167\n",
      "No data for provider_id 76361\n"
     ]
    }
   ],
   "source": [
    "# use the function from above to see if q or w data files exist for the list of provider ids\n",
    "for empty_provider_id in empty_provider_ids:\n",
    "    # check q data\n",
    "    q_data_path = get_filename_mapping(q_zip_path).get(empty_provider_id)\n",
    "    w_data_path = get_filename_mapping(w_zip_path).get(empty_provider_id)\n",
    "    if q_data_path is None and w_data_path is None:\n",
    "        print(f\"No data for provider_id {empty_provider_id}\")\n",
    "    else:\n",
    "        print(f\"There was at least q or w data for provider_id {empty_provider_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So the `nuts_mapping` is actually incorrect, as it included provider_ids for which we do not have data!\n",
    "\n",
    "The question now is: Just delete these entries from the nuts_mapping? But this will mess up the order of `nuts_ids` / there will be jumps in the nuts_ids."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
