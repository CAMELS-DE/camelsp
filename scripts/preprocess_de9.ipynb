{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Niedersachsen\n",
    "\n",
    "Every federal state is represented by its own input directory and is processed into a NUTS level 2 directory containing a sub-folder for each discharge location. These folder names are derived from NUTS and reflect the CAMELS id. The NUTS level 2 code for Niedersachsen is `DE9`.\n",
    "\n",
    "To pre-process the data, you need to write (at least) two functions. One should extract all metadata and condense it into a single `pandas.DataFrame`. This is used to build the folder structure and derive the ids.\n",
    "The second function has to take an id, as provided by the state authorities, called `provider_id` and return a `pandas.DataFrame` with the transformed data. The dataframe needs the three columns `['date', 'q' | 'w', 'flag']`.\n",
    "\n",
    "For easier and unified output handling, the `camelsp` package contains a context object called `Bundesland`. It takes a number of names and abbreviations to identify the correct federal state and returns an object that holds helper and save functions.\n",
    "\n",
    "The context saves files as needed and can easily be changed to save files with different strategies, ie. fill missing data with NaN, merge data into a single file, create files for each variable or pack everything together into a netcdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from typing import Union, Dict, List\n",
    "from datetime import datetime as dt\n",
    "from dateparser import parse\n",
    "import warnings\n",
    "\n",
    "from camelsp import Bundesland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The context can also be instantiated as any regular Python class, ie. to load only the default input data path, that we will user later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mirko/Dropbox/python/camelsp/input_data/NiS_Niedersachsen'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the context also makes the input path available, if camelsp was install locally\n",
    "BASE = Bundesland('niedersachsen').input_path\n",
    "BASE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse data\n",
    "\n",
    "Niedersachen produced only one file. I guess this needs to be pivoted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MESSSTELLE_NR</th>\n",
       "      <th>DATUM</th>\n",
       "      <th>LANGNAME</th>\n",
       "      <th>BEZEICHNUNG</th>\n",
       "      <th>KENNUNG_ID</th>\n",
       "      <th>WERT</th>\n",
       "      <th>EINHEIT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3183101</td>\n",
       "      <td>10.01.85</td>\n",
       "      <td>Sudendorf</td>\n",
       "      <td>Abfluss Tagesmittelwert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.853</td>\n",
       "      <td>m³/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3183101</td>\n",
       "      <td>11.01.85</td>\n",
       "      <td>Sudendorf</td>\n",
       "      <td>Abfluss Tagesmittelwert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.853</td>\n",
       "      <td>m³/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3183101</td>\n",
       "      <td>12.01.85</td>\n",
       "      <td>Sudendorf</td>\n",
       "      <td>Abfluss Tagesmittelwert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.853</td>\n",
       "      <td>m³/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3183101</td>\n",
       "      <td>13.01.85</td>\n",
       "      <td>Sudendorf</td>\n",
       "      <td>Abfluss Tagesmittelwert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.772</td>\n",
       "      <td>m³/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3183101</td>\n",
       "      <td>07.09.87</td>\n",
       "      <td>Sudendorf</td>\n",
       "      <td>Abfluss Tagesmittelwert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.938</td>\n",
       "      <td>m³/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195557</th>\n",
       "      <td>3183101</td>\n",
       "      <td>05.01.85</td>\n",
       "      <td>Sudendorf</td>\n",
       "      <td>Abfluss Tagesmittelwert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.030</td>\n",
       "      <td>m³/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195558</th>\n",
       "      <td>3183101</td>\n",
       "      <td>06.01.85</td>\n",
       "      <td>Sudendorf</td>\n",
       "      <td>Abfluss Tagesmittelwert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.030</td>\n",
       "      <td>m³/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195559</th>\n",
       "      <td>3183101</td>\n",
       "      <td>07.01.85</td>\n",
       "      <td>Sudendorf</td>\n",
       "      <td>Abfluss Tagesmittelwert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.800</td>\n",
       "      <td>m³/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195560</th>\n",
       "      <td>3183101</td>\n",
       "      <td>08.01.85</td>\n",
       "      <td>Sudendorf</td>\n",
       "      <td>Abfluss Tagesmittelwert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.200</td>\n",
       "      <td>m³/s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4195561</th>\n",
       "      <td>3183101</td>\n",
       "      <td>09.01.85</td>\n",
       "      <td>Sudendorf</td>\n",
       "      <td>Abfluss Tagesmittelwert</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.938</td>\n",
       "      <td>m³/s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4195562 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         MESSSTELLE_NR     DATUM   LANGNAME              BEZEICHNUNG  \\\n",
       "0              3183101  10.01.85  Sudendorf  Abfluss Tagesmittelwert   \n",
       "1              3183101  11.01.85  Sudendorf  Abfluss Tagesmittelwert   \n",
       "2              3183101  12.01.85  Sudendorf  Abfluss Tagesmittelwert   \n",
       "3              3183101  13.01.85  Sudendorf  Abfluss Tagesmittelwert   \n",
       "4              3183101  07.09.87  Sudendorf  Abfluss Tagesmittelwert   \n",
       "...                ...       ...        ...                      ...   \n",
       "4195557        3183101  05.01.85  Sudendorf  Abfluss Tagesmittelwert   \n",
       "4195558        3183101  06.01.85  Sudendorf  Abfluss Tagesmittelwert   \n",
       "4195559        3183101  07.01.85  Sudendorf  Abfluss Tagesmittelwert   \n",
       "4195560        3183101  08.01.85  Sudendorf  Abfluss Tagesmittelwert   \n",
       "4195561        3183101  09.01.85  Sudendorf  Abfluss Tagesmittelwert   \n",
       "\n",
       "         KENNUNG_ID   WERT EINHEIT  \n",
       "0               NaN  0.853    m³/s  \n",
       "1               NaN  0.853    m³/s  \n",
       "2               NaN  0.853    m³/s  \n",
       "3               NaN  0.772    m³/s  \n",
       "4               NaN  0.938    m³/s  \n",
       "...             ...    ...     ...  \n",
       "4195557         NaN  1.030    m³/s  \n",
       "4195558         NaN  1.030    m³/s  \n",
       "4195559         NaN  1.800    m³/s  \n",
       "4195560         NaN  1.200    m³/s  \n",
       "4195561         NaN  0.938    m³/s  \n",
       "\n",
       "[4195562 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_csv(os.path.join(BASE, 'exp-peg-par252.csv'), encoding='latin1', sep=';', decimal=',')\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id column is MESSSTELLE_NR\n",
    "id_column = 'MESSSTELLE_NR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abfluss Tagesmittelwert'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many different variables are there?\n",
    "names = []\n",
    "for _, df in raw.groupby(id_column):\n",
    "    names.extend(df.BEZEICHNUNG.unique().tolist())\n",
    "set(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messstellen: 282\n"
     ]
    }
   ],
   "source": [
    "# total messstellen\n",
    "N = len(raw.groupby(id_column))\n",
    "print(f\"Messstellen: {N}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New create a list of collected 'metadata' and the actual discharge data. \n",
    "\n",
    "Extract  all metadata for this federal state, without using the `Bundesland` context and then later use the context to pass extracted metadata. The Context has a function for saving *raw* metadata, that takes a `pandas.DataFrame` and needs you to identify the id column.\n",
    "Here, *raw* refers to provider metadata, that has not yet been transformed into the CAMELS-de Metadata schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 26/282 [06:50<1:07:23, 15.80s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_667/2039735223.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     })\n\u001b[1;32m     17\u001b[0m     data.append(pd.DataFrame({\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;34m'date'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATUM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;34m'q'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWERT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;34m'flag'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_667/2039735223.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     16\u001b[0m     })\n\u001b[1;32m     17\u001b[0m     data.append(pd.DataFrame({\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;34m'date'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATUM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0;34m'q'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWERT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;34m'flag'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/dateparser/conf.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"settings can only be either dict or instance of Settings class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/dateparser/__init__.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(date_string, date_formats, languages, locales, region, settings, detect_languages_function)\u001b[0m\n\u001b[1;32m     59\u001b[0m                                 region=region, settings=settings, detect_languages_function=detect_languages_function)\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_date_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_formats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/dateparser/date.py\u001b[0m in \u001b[0;36mget_date_data\u001b[0;34m(self, date_string, date_formats)\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0mdate_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mlocale\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_applicable_locales\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m             parsed_date = _DateLocaleParser.parse(\n\u001b[1;32m    452\u001b[0m                 locale, date_string, date_formats, settings=self._settings)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/dateparser/date.py\u001b[0m in \u001b[0;36m_get_applicable_locales\u001b[0;34m(self, date_string)\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_languages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetected_languages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         for locale in self._get_locale_loader().get_locales(\n\u001b[0m\u001b[1;32m    500\u001b[0m                 \u001b[0mlanguages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocales\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocales\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m                 use_given_order=self.use_given_order):\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/dateparser/languages/loader.py\u001b[0m in \u001b[0;36mget_locales\u001b[0;34m(self, languages, locales, region, use_given_order, allow_conflicting_locales)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32myield\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlocale\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \"\"\"\n\u001b[0;32m--> 113\u001b[0;31m         for _, locale in self._load_data(\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0mlanguages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocales\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocales\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0muse_given_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_given_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/dateparser/languages/loader.py\u001b[0m in \u001b[0;36m_load_data\u001b[0;34m(self, languages, locales, region, use_given_order, allow_conflicting_locales)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_given_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             locale_dict = OrderedDict(sorted(locale_dict.items(),\n\u001b[0m\u001b[1;32m    166\u001b[0m                                       key=lambda x: language_order.index(x[1][0])))\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# result container\n",
    "meta = []\n",
    "data = []\n",
    "\n",
    "# group by id\n",
    "N = len(raw.groupby(id_column))\n",
    "\n",
    "# go for it\n",
    "for nr, df in tqdm(raw.groupby(id_column)):\n",
    "    meta.append({\n",
    "        id_column: str(nr),\n",
    "        'BEZEICHNUNG': df.BEZEICHNUNG.unique().tolist(),\n",
    "        'EINHEIT': df.EINHEIT.unique().tolist(),\n",
    "        'LANGNAME': df.LANGNAME.unique().tolist(),\n",
    "        'KENNUNG_ID': df.KENNUNG_ID.unique().tolist()\n",
    "    })\n",
    "    data.append(pd.DataFrame({\n",
    "        'date': [d.date() if isinstance(d, dt) else parse(d) for d in df.DATUM],\n",
    "        'q': df.WERT,\n",
    "        'flag': np.NaN\n",
    "    }))\n",
    "\n",
    "print(f\"Extracted {len(data)} timeseries\")\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metadata\n",
    "\n",
    "Ok, let's get really wild. Check that the code above produced only lists of 1 unique value per group. Otherwise the metadata would change over time for the same Messstelle and that would be a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_metadata(meta: List[dict]) -> pd.DataFrame:\n",
    "    pmeta = []\n",
    "    for i, m in enumerate(meta):\n",
    "        out = {}\n",
    "        for k, v in m.items():\n",
    "            if isinstance(v, list):\n",
    "                if len(v) == 1:\n",
    "                    out[k] = v[0]\n",
    "                else:\n",
    "                    warnings.warn(f\"Line {i + 1}: More than one value found for {k}: [{', '.join(v)}]\")\n",
    "            else:\n",
    "                out[k] = v\n",
    "        pmeta.append(out)\n",
    "    return pd.DataFrame(pmeta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally run\n",
    "\n",
    "Now, the Q and W data can be extracted along with the metadata. The cool thing is, that all the id creation, data creation, merging and the mapping from our ids to the original ids and files is done by the context. This is helpful, as we less likely screw something up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nuts_id provider_id                              path\n",
      "0  DE910000     3183101  ./DE9/DE910000/DE910000_data.csv\n",
      "1  DE910010     3346103  ./DE9/DE910010/DE910010_data.csv\n",
      "2  DE910020     3437108  ./DE9/DE910020/DE910020_data.csv\n",
      "3  DE910030     3445100  ./DE9/DE910030/DE910030_data.csv\n",
      "4  DE910040     3449100  ./DE9/DE910040/DE910040_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 26/282 [00:01<00:19, 13.44it/s]\n"
     ]
    }
   ],
   "source": [
    "with Bundesland('Niedersachsen') as bl:\n",
    "    # catch warnings\n",
    "    with warnings.catch_warnings(record=True) as warns:\n",
    "        # tidy the metadata\n",
    "        metadata = tidy_metadata(meta)\n",
    "\n",
    "        # save the metadata\n",
    "        bl.save_raw_metadata(metadata, id_column, overwrite=True)\n",
    "\n",
    "        # for reference, call the nuts-mapping as table\n",
    "        nuts_map = bl.nuts_table\n",
    "        print(nuts_map.head())\n",
    "    \n",
    "        # go for all ids\n",
    "        for meta, df in tqdm(zip(meta, data), total=N):\n",
    "            # get the id\n",
    "            provider_id = meta[id_column]\n",
    "\n",
    "            # save\n",
    "            bl.save_timeseries(df, provider_id)\n",
    "        \n",
    "        # check if there were warnings (there are warnings)\n",
    "        if len(warns) > 0:\n",
    "            log_path = bl.save_warnings(warns)\n",
    "            print(f\"There were warnings during the processing. The log can be found at: {log_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f54d8176e82297fa872ac8c77277e50c0e193f921954c1c4a0b1ae2e8be99b71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
