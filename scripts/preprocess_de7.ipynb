{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hessen\n",
    "\n",
    "Every federal state is represented by its own input directory and is processed into a NUTS level 2 directory containing a sub-folder for each discharge location. These folder names are derived from NUTS and reflect the CAMELS id. The NUTS level 2 code for Hessen is `DE7`.\n",
    "\n",
    "To pre-process the data, you need to write (at least) two functions. One should extract all metadata and condense it into a single `pandas.DataFrame`. This is used to build the folder structure and derive the ids.\n",
    "The second function has to take an id, as provided by the state authorities, called `provider_id` and return a `pandas.DataFrame` with the transformed data. The dataframe needs the three columns `['date', 'q' | 'w', 'flag']`.\n",
    "\n",
    "For easier and unified output handling, the `camelsp` package contains a context object called `Bundesland`. It takes a number of names and abbreviations to identify the correct federal state and returns an object that holds helper and save functions.\n",
    "\n",
    "The context saves files as needed and can easily be changed to save files with different strategies, ie. fill missing data with NaN, merge data into a single file, create files for each variable or pack everything together into a netcdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from pandas.errors import ParserError\n",
    "import os\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "from typing import Union, Dict\n",
    "import zipfile\n",
    "from datetime import datetime as dt\n",
    "from io import StringIO\n",
    "import warnings\n",
    "\n",
    "from camelsp import Bundesland, Station"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The context can also be instantiated as any regular Python class, ie. to load only the default input data path, that we will user later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/camel/camelsp/input_data/HE_Hessen'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the context also makes the input path available, if camelsp was install locally\n",
    "BASE = Bundesland('Hessen').input_path\n",
    "BASE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata reader\n",
    "\n",
    "Define the function that extracts / reads and eventually merges all metadata for this federal state. You can develop the function here, without using the Bundesland context and then later use the context to pass extracted metadata. The Context has a function for saving *raw* metadata, that takes a `pandas.DataFrame` and needs you to identify the id column.\n",
    "Here, *raw* refers to provider metadata, that has not yet been transformed into the CAMELS-de Metadata schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pegelname</th>\n",
       "      <th>Gewässer</th>\n",
       "      <th>Messstellen Nr.</th>\n",
       "      <th>Q seit AJ</th>\n",
       "      <th>Koordinaten X</th>\n",
       "      <th>Koordinaten Y</th>\n",
       "      <th>Koordinaten-system</th>\n",
       "      <th>Höhe              [m ü. NN]</th>\n",
       "      <th>Größe des Einzugsge-biets [km²]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelshausen</td>\n",
       "      <td>Pfieffe</td>\n",
       "      <td>42780500</td>\n",
       "      <td>1981</td>\n",
       "      <td>539203.32</td>\n",
       "      <td>5662292.03</td>\n",
       "      <td>UTM_ETRS89</td>\n",
       "      <td>171.238</td>\n",
       "      <td>116.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alsfeld</td>\n",
       "      <td>Schwalm</td>\n",
       "      <td>42880458</td>\n",
       "      <td>1968</td>\n",
       "      <td>520113.63</td>\n",
       "      <td>5622930.81</td>\n",
       "      <td>UTM_ETRS89</td>\n",
       "      <td>237.682</td>\n",
       "      <td>131.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angenrod</td>\n",
       "      <td>Antreff</td>\n",
       "      <td>42881009</td>\n",
       "      <td>1977</td>\n",
       "      <td>514566.84</td>\n",
       "      <td>5623429.65</td>\n",
       "      <td>UTM_ETRS89</td>\n",
       "      <td>280.930</td>\n",
       "      <td>58.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aßlar</td>\n",
       "      <td>Dill</td>\n",
       "      <td>25842500</td>\n",
       "      <td>1963</td>\n",
       "      <td>462040.59</td>\n",
       "      <td>5603547.93</td>\n",
       "      <td>UTM_ETRS89</td>\n",
       "      <td>153.030</td>\n",
       "      <td>693.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Auhammer</td>\n",
       "      <td>Eder</td>\n",
       "      <td>42810204</td>\n",
       "      <td>1960</td>\n",
       "      <td>473648.32</td>\n",
       "      <td>5653835.87</td>\n",
       "      <td>UTM_ETRS89</td>\n",
       "      <td>298.216</td>\n",
       "      <td>488.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Unter-Schmitten</td>\n",
       "      <td>Nidda</td>\n",
       "      <td>24810600</td>\n",
       "      <td>1967</td>\n",
       "      <td>501734.70</td>\n",
       "      <td>5587094.18</td>\n",
       "      <td>UTM_ETRS89</td>\n",
       "      <td>132.300</td>\n",
       "      <td>124.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Uttershausen</td>\n",
       "      <td>Schwalm</td>\n",
       "      <td>42882806</td>\n",
       "      <td>1958</td>\n",
       "      <td>522997.73</td>\n",
       "      <td>5657842.91</td>\n",
       "      <td>UTM_ETRS89</td>\n",
       "      <td>164.411</td>\n",
       "      <td>984.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Weilers</td>\n",
       "      <td>Bracht</td>\n",
       "      <td>24782800</td>\n",
       "      <td>1972</td>\n",
       "      <td>522136.45</td>\n",
       "      <td>5569511.02</td>\n",
       "      <td>UTM_ETRS89</td>\n",
       "      <td>140.790</td>\n",
       "      <td>111.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Windecken</td>\n",
       "      <td>Nidder</td>\n",
       "      <td>24861407</td>\n",
       "      <td>1956</td>\n",
       "      <td>491018.79</td>\n",
       "      <td>5563393.68</td>\n",
       "      <td>UTM_ETRS89</td>\n",
       "      <td>112.620</td>\n",
       "      <td>392.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ziegenhagen 1</td>\n",
       "      <td>Rautenbach</td>\n",
       "      <td>41980355</td>\n",
       "      <td>1958</td>\n",
       "      <td>552711.16</td>\n",
       "      <td>5690897.56</td>\n",
       "      <td>UTM_ETRS89</td>\n",
       "      <td>191.433</td>\n",
       "      <td>14.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pegelname    Gewässer  Messstellen Nr.  Q seit AJ  Koordinaten X  \\\n",
       "0       Adelshausen     Pfieffe         42780500       1981      539203.32   \n",
       "1           Alsfeld     Schwalm         42880458       1968      520113.63   \n",
       "2          Angenrod     Antreff         42881009       1977      514566.84   \n",
       "3             Aßlar        Dill         25842500       1963      462040.59   \n",
       "4          Auhammer        Eder         42810204       1960      473648.32   \n",
       "..              ...         ...              ...        ...            ...   \n",
       "92  Unter-Schmitten       Nidda         24810600       1967      501734.70   \n",
       "93     Uttershausen     Schwalm         42882806       1958      522997.73   \n",
       "94          Weilers      Bracht         24782800       1972      522136.45   \n",
       "95        Windecken      Nidder         24861407       1956      491018.79   \n",
       "96    Ziegenhagen 1  Rautenbach         41980355       1958      552711.16   \n",
       "\n",
       "    Koordinaten Y Koordinaten-system  Höhe              [m ü. NN]  \\\n",
       "0      5662292.03         UTM_ETRS89                      171.238   \n",
       "1      5622930.81         UTM_ETRS89                      237.682   \n",
       "2      5623429.65         UTM_ETRS89                      280.930   \n",
       "3      5603547.93         UTM_ETRS89                      153.030   \n",
       "4      5653835.87         UTM_ETRS89                      298.216   \n",
       "..            ...                ...                          ...   \n",
       "92     5587094.18         UTM_ETRS89                      132.300   \n",
       "93     5657842.91         UTM_ETRS89                      164.411   \n",
       "94     5569511.02         UTM_ETRS89                      140.790   \n",
       "95     5563393.68         UTM_ETRS89                      112.620   \n",
       "96     5690897.56         UTM_ETRS89                      191.433   \n",
       "\n",
       "    Größe des Einzugsge-biets [km²]  \n",
       "0                            116.16  \n",
       "1                            131.41  \n",
       "2                             58.74  \n",
       "3                            693.63  \n",
       "4                            488.94  \n",
       "..                              ...  \n",
       "92                           124.00  \n",
       "93                           984.98  \n",
       "94                           111.90  \n",
       "95                           392.60  \n",
       "96                            14.20  \n",
       "\n",
       "[97 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the function \n",
    "def read_meta(base_path) -> pd.DataFrame:\n",
    "    path = os.path.join(base_path,'raw_data', 'Pegel_für_Camels.xlsx')\n",
    "    meta = pd.read_excel(path)\n",
    "    return meta\n",
    "\n",
    "# test it here\n",
    "metadata = read_meta(BASE)\n",
    "\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the id column will be Messstellen Nr.\n",
    "id_column = 'Messstellen Nr.'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## file extract and parse\n",
    "\n",
    "Should be straightforward, really nice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>q</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1957-11-01</td>\n",
       "      <td>0.106</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1957-11-02</td>\n",
       "      <td>0.092</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1957-11-03</td>\n",
       "      <td>0.092</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1957-11-04</td>\n",
       "      <td>0.078</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1957-11-05</td>\n",
       "      <td>0.078</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23432</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>0.084</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23433</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>0.097</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23434</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>0.146</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23435</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>0.210</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23436</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>0.205</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23437 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date      q   flag\n",
       "0     1957-11-01  0.106   True\n",
       "1     1957-11-02  0.092   True\n",
       "2     1957-11-03  0.092   True\n",
       "3     1957-11-04  0.078   True\n",
       "4     1957-11-05  0.078   True\n",
       "...          ...    ...    ...\n",
       "23432 2021-12-27  0.084  False\n",
       "23433 2021-12-28  0.097  False\n",
       "23434 2021-12-29  0.146  False\n",
       "23435 2021-12-30  0.210  False\n",
       "23436 2021-12-31  0.205  False\n",
       "\n",
       "[23437 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_file(nr: Union[int, str], variable: str, input_path: str) -> pd.DataFrame:\n",
    "\n",
    "    # build the path to the correct subfolder:\n",
    "    path = os.path.join(input_path, variable, f\"{nr}_{variable.upper()}.txt\")\n",
    "\n",
    "    # check file\n",
    "    if not os.path.exists(path):\n",
    "        return pd.DataFrame(columns=['date', variable.lower(), 'flag'])\n",
    "    \n",
    "    # read\n",
    "    raw = pd.read_csv(path, skiprows=4, encoding='latin1', sep=' ', header=None, na_values=-777)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'date': [dt.strptime(str(_)[:8], '%Y%m%d') for _ in raw.iloc[:, 0]],\n",
    "        variable.lower(): raw.iloc[:, 1],\n",
    "    })\n",
    "\n",
    "    # set flag True before 2018 (see Anfrage-Camels-HUIG-79c1801_Spi.pdf)\n",
    "    df['flag'] = df['date'] < pd.to_datetime('2018-01-01')\n",
    "\n",
    "    return df\n",
    "\n",
    "extract_file(41980355, 'q', BASE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally run\n",
    "\n",
    "Now, the Q and W data can be extracted along with the metadata. The cool thing is, that all the id creation, data creation, merging and the mapping from our ids to the original ids and files is done by the context. This is helpful, as we less likely screw something up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nuts_id provider_id                              path\n",
      "0  DE710000    42780500  ./DE7/DE710000/DE710000_data.csv\n",
      "1  DE710010    42880458  ./DE7/DE710010/DE710010_data.csv\n",
      "2  DE710020    42881009  ./DE7/DE710020/DE710020_data.csv\n",
      "3  DE710030    25842500  ./DE7/DE710030/DE710030_data.csv\n",
      "4  DE710040    42810204  ./DE7/DE710040/DE710040_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/97 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [01:07<00:00,  1.44it/s]\n"
     ]
    }
   ],
   "source": [
    "with Bundesland('Hessen') as bl:\n",
    "    # save the metadata\n",
    "    bl.save_raw_metadata(metadata, id_column, overwrite=True)\n",
    "\n",
    "    # for reference, call the nuts-mapping as table\n",
    "    nuts_map = bl.nuts_table\n",
    "    print(nuts_map.head())\n",
    "\n",
    "    \n",
    "    with warnings.catch_warnings(record=True) as warns:\n",
    "        for provider_id in tqdm(metadata[id_column].values.astype(str)):\n",
    "            # get q\n",
    "            q = extract_file(provider_id, 'q', bl.input_path)\n",
    "            w = extract_file(provider_id, 'w', bl.input_path)\n",
    "\n",
    "            bl.save_timeseries(q, provider_id)\n",
    "            bl.save_timeseries(w, provider_id)\n",
    "\n",
    "        # check if there were warnings (there are warnings)\n",
    "        if len(warns) > 0:\n",
    "            log_path = bl.save_warnings(warns)\n",
    "            print(f\"There were warnings during the processing. The log can be found at: {log_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2c57ebfed52ffd848a0d2f36f1ea9c0a9060c9b67397fbb725d6aa92a9494b08"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
